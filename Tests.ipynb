{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd998c20",
   "metadata": {},
   "source": [
    "# Deep Learning Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28588085",
   "metadata": {},
   "source": [
    "## 1. Linear Regression\n",
    "https://d2l.ai/chapter_linear-networks/linear-regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eab6bb",
   "metadata": {},
   "source": [
    "### 1.1. Linear regression from scratch in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a84b5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3: 3.21178522830051\n",
      "2/3: 0.006472579643693114\n",
      "3/3: 6.409211600749226e-05\n",
      "\n",
      "w = [ 2.00056852 -3.39996605]\n",
      "b = 4.199792013095364\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define the true weights and bias of the model\n",
    "w_true = np.array([2, -3.4])\n",
    "b_true = 4.2\n",
    "\n",
    "# Generate inputs (standard normal distribution) and derive the outputs (with some noise)\n",
    "number_examples = 1000\n",
    "number_features = len(w_true)\n",
    "X = np.random.default_rng().normal(0, 1, (number_examples, number_features))\n",
    "y = np.matmul(X, w_true)+b_true+np.random.default_rng().normal(0, 0.01, number_examples)\n",
    "\n",
    "# Define the parameters for the training\n",
    "number_epochs = 3\n",
    "batch_size = 10\n",
    "lr = 0.03\n",
    "\n",
    "# Initialize the weights and bias to recover\n",
    "w = np.random.default_rng().normal(0, 1, number_features)\n",
    "b = 0\n",
    "\n",
    "# Initialize a list for the mean loss over the minibatches of every epoch\n",
    "epoch_loss = np.zeros(number_epochs)\n",
    "\n",
    "# Loop over the epochs\n",
    "for i in range(number_epochs):\n",
    "    \n",
    "    # Generate the indices for all the examples and shuffle them\n",
    "    example_indices = np.arange(number_examples)\n",
    "    random.shuffle(example_indices)\n",
    "    \n",
    "    # Initialize a list for the mean loss over the examples of every minibatch\n",
    "    batch_loss = []\n",
    "    \n",
    "    # Loop over the examples in minibatches\n",
    "    for j in np.arange(0, number_examples, batch_size):\n",
    "        \n",
    "        # Get the indices of the examples for one minibatch (randomized) \n",
    "        batch_indices = example_indices[j:min(j+batch_size, number_examples)]\n",
    "        \n",
    "        # Get the inputs and outputs for the current minibatch\n",
    "        X_batch = X[batch_indices, :]\n",
    "        y_batch = y[batch_indices]\n",
    "        \n",
    "        # Compute the predicted outputs\n",
    "        y_hat = np.matmul(X_batch, w) + b\n",
    "        \n",
    "        # Compute the loss between the predicted and true outputs\n",
    "        l = np.mean(0.5*np.power(y_hat-y_batch, 2))\n",
    "        \n",
    "        # Save the loss for the current minibatch\n",
    "        batch_loss.append(l)\n",
    "        \n",
    "        # Update the weights and bias using stochastic gradient descent (SGD)\n",
    "        w = w - lr*np.mean(X_batch*(y_hat-y_batch)[:, np.newaxis], axis=0)\n",
    "        b = b - lr*np.mean(y_hat-y_batch, axis=0)\n",
    "        \n",
    "    # Save the mean loss for the current epoch\n",
    "    epoch_loss[i] = np.mean(batch_loss)\n",
    "    \n",
    "    # Print the progress\n",
    "    print(f'{i+1}/{number_epochs}: {epoch_loss[i]}')\n",
    "    \n",
    "# Print the predicted weights and bias\n",
    "print('')\n",
    "print(f'w = {w}')\n",
    "print(f'b = {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb9d9b",
   "metadata": {},
   "source": [
    "### 1.2. Linear regression from scratch in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b5b48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3: 2.3689355850219727\n",
      "2/3: 0.005317648872733116\n",
      "3/3: 6.585512164747342e-05\n",
      "\n",
      "w = tensor([ 2.0005, -3.3999], requires_grad=True)\n",
      "b = tensor([4.1989], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "# Define the true weights and bias of the model\n",
    "w_true = torch.tensor([2, -3.4])\n",
    "b_true = 4.2\n",
    "\n",
    "# Generate inputs and derive outputs\n",
    "number_examples = 1000\n",
    "number_features = len(w_true)\n",
    "X = torch.normal(0, 1, (number_examples, number_features))\n",
    "y = torch.matmul(X, w_true)+b_true+torch.normal(0, 0.01, [number_examples]) # [number_examples]?\n",
    "\n",
    "# Define a function to read the dataset in random minibatches\n",
    "def batch(X, y, batch_size):\n",
    "    \n",
    "    # Generate the indices for all the examples and shuffle them\n",
    "    number_examples = X.shape[0]\n",
    "    example_indices = list(range(number_examples))\n",
    "    random.shuffle(example_indices)\n",
    "    \n",
    "    # Loop over the examples in batches\n",
    "    for i in range(0, number_examples, batch_size):\n",
    "        \n",
    "        # Get the indices of the (randomized) examples for one minibatch\n",
    "        batch_indices = example_indices[i:min(i+batch_size, number_examples)]\n",
    "        \n",
    "        # Return the input and output minibatch and continue the iteration in the function\n",
    "        yield X[batch_indices], y[batch_indices]\n",
    "\n",
    "# Define the parameters for the training\n",
    "number_epochs = 3\n",
    "batch_size = 10\n",
    "lr = 0.03\n",
    "\n",
    "# Initialize the weights and bias to recover, requiring the gradients to be computed\n",
    "w = torch.normal(0, 1, [number_features], requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# Initialize an array for the mean loss over the minibatches of every epoch\n",
    "epoch_loss = torch.zeros(number_epochs)\n",
    "        \n",
    "# Loop over the epochs\n",
    "for i in range(number_epochs):\n",
    "    \n",
    "    # Initialize a list for the mean loss over the examples of every minibatch\n",
    "    batch_loss = []\n",
    "    \n",
    "    # Loop over the examples in minibatches\n",
    "    for X_batch, y_batch in batch(X, y, batch_size):\n",
    "        \n",
    "        # Compute the predicted outputs\n",
    "        y_hat = torch.matmul(X_batch, w) + b\n",
    "        \n",
    "        # Compute the loss between the predicted and true outputs\n",
    "        l = 0.5*(y_hat-y_batch)**2\n",
    "        \n",
    "        # Compute the gradient on l with respect to w and b\n",
    "        # (sum and not mean as the gradients will be divided by the batch size during SGD)\n",
    "        l.sum().backward()\n",
    "        \n",
    "        # Temporarily sets all of the requires_grad flags to false\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Save the mean loss for the current minibatch\n",
    "            batch_loss.append(l.mean())\n",
    "            \n",
    "            # Update the weights and bias using SGD\n",
    "            # (use augmented assignments to avoid modifying existing variables)\n",
    "            w -= lr*w.grad/len(l)\n",
    "            b -= lr*b.grad/len(l)\n",
    "            \n",
    "            # Set the gradients to zeros to avoid accumulating gradients\n",
    "            w.grad.zero_()\n",
    "            b.grad.zero_()\n",
    "            \n",
    "    # Update the mean loss for the current epoch\n",
    "    epoch_loss[i] = sum(batch_loss)/len(batch_loss)\n",
    "    \n",
    "    # Print the progress\n",
    "    print(f'{i+1}/{number_epochs}: {epoch_loss[i]}')\n",
    "    \n",
    "# Print the predicted weights and bias\n",
    "print('')\n",
    "print(f'w = {w}')\n",
    "print(f'b = {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb27c36f",
   "metadata": {},
   "source": [
    "### 1.3. Linear regression using APIs in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "219ae16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3: 2.879786729812622\n",
      "2/3: 0.0001097871208912693\n",
      "3/3: 9.997401502914727e-05\n",
      "\n",
      "w = tensor([[ 2.0003, -3.3999]])\n",
      "b = tensor([4.2000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "\n",
    "# Define the true weights and bias of the model\n",
    "w_true = torch.tensor([2, -3.4])\n",
    "b_true = 4.2\n",
    "\n",
    "# Generate inputs and derive outputs\n",
    "number_examples = 1000\n",
    "number_features = len(w_true)\n",
    "X = torch.normal(0, 1, (number_examples, number_features))\n",
    "y = torch.matmul(X, w_true)+b_true+torch.normal(0, 0.01, [number_examples]) # [number_examples]?\n",
    "\n",
    "# Define a function to read the dataset in random minibatches\n",
    "def batch(X, y, batch_size):\n",
    "    \n",
    "    # Construct a PyTorch data iterator (?)\n",
    "    data_set = data.TensorDataset(*(X, y))\n",
    "    return data.DataLoader(data_set, batch_size, shuffle=True)\n",
    "\n",
    "# Define the parameters for the training\n",
    "number_epochs = 3\n",
    "batch_size = 10\n",
    "lr = 0.03\n",
    "\n",
    "# Define the model (as a stack of layers) and add a fully-connected layer\n",
    "model = nn.Sequential(nn.Linear(number_features, 1))\n",
    "\n",
    "# Initialize the parameters\n",
    "model[0].weight.data.normal_(0, 0.01)\n",
    "model[0].bias.data.fill_(0)\n",
    "\n",
    "# Define the loss function (mean squared error, without the 0.5 factor)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# Define the optimization algorithm (SGD)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Initialize an array for the mean loss over the minibatches of every epoch\n",
    "epoch_loss = torch.zeros(number_epochs)\n",
    "\n",
    "# Loop over the epochs\n",
    "for i in range(number_epochs):\n",
    "    \n",
    "    # Initialize a list for the mean loss over the examples of every minibatch\n",
    "    batch_loss = []\n",
    "    \n",
    "    # Loop over the examples in minibatches\n",
    "    for X_batch, y_batch in batch(X, y, batch_size):\n",
    "        \n",
    "        # Compute the predicted outputs\n",
    "        y_hat = model(X_batch)\n",
    "        \n",
    "        # Compute the loss between the predicted and true outputs\n",
    "        l = loss(y_hat, y_batch[:, None])\n",
    "        \n",
    "        # Save the loss for the current minibatch (no with torch.no_grad()?)\n",
    "        batch_loss.append(l)\n",
    "        \n",
    "        # Set the gradients to zero (.zero_grad()?)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Computes the gradient (no .sum?)\n",
    "        l.backward()\n",
    "        \n",
    "        # Performs a single parameter update\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Update the mean loss for the current epoch\n",
    "    epoch_loss[i] = sum(batch_loss)/len(batch_loss)\n",
    "        \n",
    "    # Print the progress\n",
    "    print(f'{i+1}/{number_epochs}: {epoch_loss[i]}')\n",
    "    \n",
    "# Print the predicted weights and bias\n",
    "print('')\n",
    "print(f'w = {model[0].weight.data}')\n",
    "print(f'b = {model[0].bias.data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d77f99",
   "metadata": {},
   "source": [
    "### 1.4. Linear regression using higher-level APIs in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ef4ff12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 1s 417us/step - loss: 2.8675\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 0s 354us/step - loss: 1.0620e-04\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 0s 340us/step - loss: 9.6979e-05\n",
      "\n",
      "w = [[ 1.9992182]\n",
      " [-3.4001048]]\n",
      "b = [4.199602]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the true weights and bias of the model\n",
    "w_true = np.array([2, -3.4])\n",
    "b_true = 4.2\n",
    "\n",
    "# Generate inputs and derive outputs\n",
    "number_examples = 1000\n",
    "number_features = len(w_true)\n",
    "X = np.random.default_rng().normal(0, 1, (number_examples, number_features))\n",
    "y = np.matmul(X, w_true)+b_true+np.random.default_rng().normal(0, 0.01, number_examples)\n",
    "\n",
    "# Define the parameters for the training\n",
    "number_epochs = 3\n",
    "batch_size = 10\n",
    "lr = 0.03\n",
    "\n",
    "# Define the model (as a stack of layers) and add a densely-connected NN layer with initialized parameters\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1, kernel_initializer=tf.initializers.RandomNormal(mean=0, stddev=0.01), \\\n",
    "                                                   bias_initializer='zeros')])\n",
    "\n",
    "# Configure the model for training with stochastic gradient descent optimizer and mean squared error loss\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=lr),\n",
    "              loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "# Train the model given the batch size and number of epochs\n",
    "model.fit(x=X, y=y, batch_size=batch_size, epochs=number_epochs, verbose=1)\n",
    "\n",
    "# Print the predicted weights and bias\n",
    "print('')\n",
    "print(f'w = {model.get_weights()[0]}')\n",
    "print(f'b = {model.get_weights()[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5ccf99",
   "metadata": {},
   "source": [
    "## 2. Softmax Regression\n",
    "https://d2l.ai/chapter_linear-networks/softmax-regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f958cf",
   "metadata": {},
   "source": [
    "### 2.1. Fashion-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b555412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x144 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Get the Fashion-MNIST dataset, with train and test inputs and outputs\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the inputs\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "# Translate the outputs into labels\n",
    "label_list = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "label_train = [label_list[i] for i in y_train]\n",
    "label_test = [label_list[i] for i in y_test]\n",
    "\n",
    "# Show a single example for the different classes\n",
    "number_classes = len(label_list)\n",
    "plt.figure(figsize=(14, 2))\n",
    "for i in range(number_classes):\n",
    "    j = np.where(y_train==i)[0][0]\n",
    "    plt.subplot(1, number_classes, i+1)\n",
    "    plt.imshow(X_train[j, :, :], cmap=\"binary\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(label_list[i])\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fce402",
   "metadata": {},
   "source": [
    "### 2.2. Softmax regression from scratch in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3672ad3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10: train_loss=0.648; train_accuracy=0.751; test_accuracy=0.794\n",
      "2/10: train_loss=0.544; train_accuracy=0.782; test_accuracy=0.806\n",
      "3/10: train_loss=0.495; train_accuracy=0.797; test_accuracy=0.811\n",
      "4/10: train_loss=0.465; train_accuracy=0.806; test_accuracy=0.825\n",
      "5/10: train_loss=0.444; train_accuracy=0.812; test_accuracy=0.818\n",
      "6/10: train_loss=0.428; train_accuracy=0.817; test_accuracy=0.830\n",
      "7/10: train_loss=0.416; train_accuracy=0.821; test_accuracy=0.830\n",
      "8/10: train_loss=0.405; train_accuracy=0.824; test_accuracy=0.823\n",
      "9/10: train_loss=0.397; train_accuracy=0.826; test_accuracy=0.827\n",
      "10/10: train_loss=0.390; train_accuracy=0.828; test_accuracy=0.834\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "# Get the train and test inputs and outputs\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "number_train = len(X_train)\n",
    "number_test = len(X_test)\n",
    "\n",
    "# Normalize and flatten the inputs\n",
    "input_size = np.size(X_train[0])\n",
    "X_train = np.reshape(X_train/255, (number_train, input_size))\n",
    "X_test = np.reshape(X_test/255, (number_test, input_size))\n",
    "\n",
    "# Derive one-hot versions of the train outputs\n",
    "output_size = 10\n",
    "y_train1 = np.zeros((number_train, output_size))\n",
    "for i in range(number_train): y_train1[i, y_train[i]] = 1\n",
    "\n",
    "# Define the parameters for the training\n",
    "number_epochs = 10\n",
    "batch_size = 256\n",
    "lr = 0.1\n",
    "\n",
    "# Initialize the weights and bias to recover\n",
    "W = np.random.default_rng().normal(0, 0.01, size=(input_size, output_size)) # 0.01?\n",
    "b = np.zeros(output_size)\n",
    "\n",
    "# Initialize lists for the mean train loss and accuracy over the minibatches for every epoch\n",
    "train_loss = [[]]*number_epochs\n",
    "train_accuracy = [[]]*number_epochs\n",
    "\n",
    "# Initialize a list for the test accuracy overall for every epoch\n",
    "test_accuracy = [None]*number_epochs\n",
    "\n",
    "# Loop over the epochs\n",
    "for i in range(number_epochs):\n",
    "    \n",
    "    # Generate random indices for all the train examples\n",
    "    train_indices = np.arange(number_train)\n",
    "    random.shuffle(train_indices)\n",
    "    \n",
    "    # Loop over the train examples in minibatches\n",
    "    for j in np.arange(0, number_train, batch_size):\n",
    "        \n",
    "        # Get the indices of the train examples for one minibatch\n",
    "        batch_indices = train_indices[j:min(j+batch_size, number_train)]\n",
    "        \n",
    "        # Get the train inputs and outputs for the minibatch\n",
    "        X_batch = X_train[batch_indices, :]\n",
    "        y_batch = y_train[batch_indices]\n",
    "        y_batch1 = y_train1[batch_indices]\n",
    "        \n",
    "        # Compute the predicted outputs (logits)\n",
    "        o = np.matmul(X_batch, W) + b\n",
    "        \n",
    "        # Compute the softmax of the logits (indirectly to avoid numerical stability issues)\n",
    "        o = o-np.max(o, axis=1)[:, np.newaxis]\n",
    "        o_exp = np.exp(o)\n",
    "        y_hat = o_exp/np.sum(o_exp, axis=1)[:, np.newaxis]\n",
    "        \n",
    "        # Compute the mean cross-entropy loss over the minibatch\n",
    "        l = np.mean(np.log(np.sum(o_exp, axis=1)-np.sum(y_batch1*o, axis=1)))\n",
    "        train_loss[i].append(l)\n",
    "        \n",
    "        # Compute the mean accuracy over the minibatch\n",
    "        a = np.mean(np.argmax(y_hat, axis=1)==y_batch)\n",
    "        train_accuracy[i].append(a)\n",
    "        \n",
    "        # Update the weights and bias using SGD\n",
    "        dl = y_hat-y_batch1\n",
    "        W = W-lr*np.matmul(X_batch.T, dl)/np.shape(X_batch)[0]\n",
    "        b = b-lr*np.mean(dl, axis=0)\n",
    "        \n",
    "    # Derive the mean train loss and accuracy for the current epoch\n",
    "    train_loss[i] = np.mean(train_loss[i])\n",
    "    train_accuracy[i] = np.mean(train_accuracy[i])\n",
    "    \n",
    "    # Compute the test outputs and derive the test accuracy for the current epoch\n",
    "    o = np.matmul(X_test, W) + b\n",
    "    o = o-np.max(o, axis=1)[:, np.newaxis]\n",
    "    o_exp = np.exp(o)\n",
    "    y_hat = o_exp/np.sum(o_exp, axis=1)[:, np.newaxis]\n",
    "    test_accuracy[i] = np.mean(np.argmax(y_hat, axis=1)==y_test)\n",
    "    \n",
    "    # Print the progress\n",
    "    print(f'{i+1}/{number_epochs}: train_loss={train_loss[i]:.3f}; train_accuracy={train_accuracy[i]:.3f}; test_accuracy={test_accuracy[i]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294bdf78",
   "metadata": {},
   "source": [
    "### 2.3. Softmax regression from scratch in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c1fded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "\n",
    "# Get the dataset (convert the image data from PIL type to 32-bit floating point tensors in [0, 1])\n",
    "fmnist_train = torchvision.datasets.FashionMNIST(root=\"data\", train=True, download=True, \n",
    "                                                 transform=torchvision.transforms.ToTensor())\n",
    "fmnist_test = torchvision.datasets.FashionMNIST(root=\"data\", train=False, download=True,\n",
    "                                                transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# Initialize the parameters to recover, requiring the gradients to be computed\n",
    "input_size = np.prod(np.shape(fmnist_train[0][0]))\n",
    "output_size = 10\n",
    "W = torch.normal(0, 0.01, size=(input_size, output_size), requires_grad=True)\n",
    "b = torch.zeros(output_size, requires_grad=True)\n",
    "\n",
    "\n",
    "\n",
    "number_train = len(fmnist_train)\n",
    "number_test = len(fmnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e6300d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = fmnist_train[1][0][0].numpy().astype(float)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26ba7ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0600, 0.0900, 0.0470, 0.6543, 0.1486],\n",
       "        [0.2267, 0.0501, 0.2282, 0.0854, 0.4096]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    return X_exp / X_exp.sum(1, keepdim=True)\n",
    "\n",
    "X = torch.normal(0, 1, (2, 5))\n",
    "X_prob = softmax(X)\n",
    "X_prob, X_prob.sum(1)\n",
    "\n",
    "softmax(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06f16ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.matmul(reshape(X, (number_train, input_size)), W) + b\n",
    "o_exp = torch.exp(o)\n",
    "y = o_exp / o_exp.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc366f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

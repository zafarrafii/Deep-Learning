{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Single neuron and linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01.1 Create a function (single linear neuron) with some inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define the true weights and bias for a single linear neuron\n",
    "# (see also http://d2l.ai/chapter_linear-networks/linear-regression-scratch.html)\n",
    "true_weights = np.array([2, -3.4])\n",
    "true_bias = 4.2\n",
    "\n",
    "# Create some inputs using a standard normal distribution\n",
    "number_examples = 1000\n",
    "number_features = len(true_weights)\n",
    "true_inputs = np.random.normal(loc=0.0, scale=1.0, size=(number_examples, number_features))\n",
    "\n",
    "# Create some noise for all the examples using a normal distribution\n",
    "true_noise = np.random.normal(loc=0.0, scale=0.01, size=number_examples)\n",
    "    \n",
    "# Compute the true outputs using the inputs, and the true weights, bias, and noise\n",
    "true_outputs = np.matmul(true_inputs, true_weights) + true_bias + true_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01.2. Learn the parameters of the neuron using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; loss: 2.8178068093399515\n",
      "Epoch: 1; loss: 0.008657554420596639\n",
      "Epoch: 2; loss: 7.830017943958494e-05\n",
      "Epoch: 3; loss: 5.141891440363032e-05\n",
      "Epoch: 4; loss: 5.1363440814342625e-05\n",
      "Epoch: 5; loss: 5.1365079908663894e-05\n",
      "Epoch: 6; loss: 5.136518882777341e-05\n",
      "Epoch: 7; loss: 5.136519515922528e-05\n",
      "Epoch: 8; loss: 5.136519552823079e-05\n",
      "Epoch: 9; loss: 5.1365195549856344e-05\n",
      "\n",
      "Predicted weights: [ 1.99999494 -3.40075876]\n",
      "Predicted bias: 4.200677829374865\n"
     ]
    }
   ],
   "source": [
    "# Define the training parameters\n",
    "number_epochs = 10\n",
    "batch_size = 10\n",
    "learning_rate = 0.03\n",
    "\n",
    "# Initialize the predicted weights and bias\n",
    "predicted_weights = np.random.normal(loc=0.0, scale=0.01, size=number_features)\n",
    "predicted_bias = 0\n",
    "\n",
    "# Initialize the loss for all the batches\n",
    "number_batches = int(np.ceil(number_examples/batch_size))\n",
    "predicted_loss = np.zeros(number_batches)\n",
    "\n",
    "# Loop over the epochs\n",
    "for i in range(number_epochs):\n",
    "    \n",
    "    # Loop over the batches\n",
    "    k = 0\n",
    "    for j in range(0, number_examples, batch_size):\n",
    "        \n",
    "        # Derive the end index of the batch\n",
    "        j2 = min(j+batch_size, number_examples)\n",
    "    \n",
    "        # Compute the predicted outputs using the inputs, and the predicted weights and bias\n",
    "        predicted_outputs = np.matmul(true_inputs[j:j2, :], predicted_weights) + predicted_bias\n",
    "\n",
    "        # Compute the difference between the predicted outputs and the true outputs\n",
    "        output_differences = predicted_outputs-true_outputs[j:j2]\n",
    "\n",
    "        # Compute the loss using the mean squared error\n",
    "        predicted_loss[k] = np.mean(0.5*np.power(output_differences, 2))\n",
    "        \n",
    "        # Do not need to make the last updates after computing the last loss\n",
    "        if i < number_epochs-1 or k < number_batches-1:\n",
    "            \n",
    "            # Update the predicted weights and bias using gradient descent, with the derivative of the loss function\n",
    "            predicted_weights -= learning_rate*np.mean(true_inputs[j:j2, :]*(output_differences)[:, np.newaxis], axis=0)\n",
    "            predicted_bias -= learning_rate*np.mean(output_differences, axis=0)\n",
    "            \n",
    "        # Update the index\n",
    "        k = k+1\n",
    "    \n",
    "    # Print the epoch and loss\n",
    "    print(f\"Epoch: {i}; loss: {np.mean(predicted_loss)}\")\n",
    "    \n",
    "# Print the predicted weights and bias\n",
    "print(\"\")\n",
    "print(f\"Predicted weights: {predicted_weights}\")\n",
    "print(f\"Predicted bias: {predicted_bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01.3. Learn the parameters of the neuron using gradient descent in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s 354us/step - loss: 8.5697\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 343us/step - loss: 1.5144e-04\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 354us/step - loss: 1.0111e-04\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 354us/step - loss: 9.9907e-05\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 374us/step - loss: 9.6224e-05\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 343us/step - loss: 9.2783e-05\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 343us/step - loss: 1.0346e-04\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 343us/step - loss: 1.0498e-04\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 343us/step - loss: 9.9771e-05\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 354us/step - loss: 9.7006e-05\n",
      "\n",
      "Predicted weights: [ 1.9996102 -3.3997617]\n",
      "Predicted bias: 4.199385166168213\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the training parameters\n",
    "number_epochs = 10\n",
    "batch_size = 10\n",
    "learning_rate = 0.03\n",
    "\n",
    "# Initialize the model (as a feedforward NN)\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add an input with the number of features\n",
    "model.add(tf.keras.Input(shape=number_features))\n",
    "\n",
    "# Add a densely-connected NN layer without activation and with initialized weights and bias\n",
    "model.add(tf.keras.layers.Dense(1, activation=None, \\\n",
    "                                kernel_initializer=tf.initializers.RandomNormal(mean=0, stddev=0.01), \\\n",
    "                                bias_initializer=\"zeros\"))\n",
    "\n",
    "# Configure the model for training with gradient descent optimizer and mean squared error loss\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss=\"mean_squared_error\")\n",
    "\n",
    "# Train the model give the batch size and number of epochs\n",
    "model.fit(x=true_inputs, y=true_outputs, batch_size=batch_size, epochs=number_epochs, verbose=1)\n",
    "\n",
    "# Print the predicted weights and bias\n",
    "print(\"\")\n",
    "print(f\"Predicted weights: {model.get_weights()[0][:, 0]}\")\n",
    "print(f\"Predicted bias: {model.get_weights()[1][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01.4. Learn the parameters of the neuron using an evolutionary algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; loss: 26.16919771857581\n",
      "Epoch: 1; loss: 15.89573684352735\n",
      "Epoch: 2; loss: 8.374283380005487\n",
      "Epoch: 3; loss: 2.9675768340124478\n",
      "Epoch: 4; loss: 0.38137886645304675\n",
      "Epoch: 5; loss: 0.0005220220825590036\n",
      "Epoch: 6; loss: 0.00048325837539071447\n",
      "Epoch: 7; loss: 0.0005137403673791562\n",
      "Epoch: 8; loss: 0.0005089096714666468\n",
      "Epoch: 9; loss: 0.0004962522573057658\n",
      "\n",
      "Predicted weights: [ 1.9938385 -3.4027235]\n",
      "Predicted bias: 4.209371000895826\n"
     ]
    }
   ],
   "source": [
    "# Define the training parameters\n",
    "number_epochs = 10\n",
    "batch_size = 10\n",
    "number_individuals = 10\n",
    "number_parents = 2\n",
    "mutation_rate = 0.01\n",
    "\n",
    "# Initialize the predicted weights and bias for all the individuals\n",
    "predicted_weights = np.random.normal(loc=0.0, scale=0.01, size=(number_features, number_individuals))\n",
    "predicted_bias = np.zeros((1, number_individuals))\n",
    "\n",
    "# Initialize the loss for all the batches and for all the individuals\n",
    "number_batches = int(np.ceil(number_examples/batch_size))\n",
    "predicted_loss = np.zeros((number_batches, number_individuals))\n",
    "\n",
    "# Loop over the epochs\n",
    "for i in range(number_epochs):\n",
    "    \n",
    "    # Loop over the batches\n",
    "    k = 0\n",
    "    for j in range(0, number_examples, batch_size):\n",
    "        \n",
    "        # Derive the end index of the batch\n",
    "        j2 = min(j+batch_size, number_examples)\n",
    "    \n",
    "        # Compute the predicted outputs using the inputs, and the predicted weights and bias, for every individual\n",
    "        predicted_outputs = np.matmul(true_inputs[j:j2, :], predicted_weights) + predicted_bias\n",
    "\n",
    "        # Compute the loss using the mean squared error, for every individual\n",
    "        predicted_loss[k, :] = np.mean(np.power(predicted_outputs-true_outputs[j:j2, np.newaxis], 2), axis=0)\n",
    "        \n",
    "        # Do not need to make the last updates after computing the last loss\n",
    "        if i < number_epochs-1 or k < number_batches-1:\n",
    "        \n",
    "            # Get the indices of the parents (the fittest individuals)\n",
    "            parent_indices = np.argsort(predicted_loss[k, :])[0:number_parents]\n",
    "\n",
    "            # Compute the mutation scale using the root mean square error\n",
    "#             mutation_scale = mutation_rate*np.mean(np.sqrt(predicted_loss[k, parent_indices]))\n",
    "            mutation_scale = mutation_rate\n",
    "            \n",
    "            # Update the predicted weights and bias using evolutionary algorithm, doing crossover and mutation\n",
    "            predicted_weights = np.mean(predicted_weights[:, parent_indices], axis=1)[:, np.newaxis] \\\n",
    "            + np.random.normal(loc=0.0, scale=mutation_scale, size=(number_features, number_individuals))\n",
    "            predicted_bias = np.mean(predicted_bias[:, parent_indices]) \\\n",
    "            + np.random.normal(loc=0.0, scale=mutation_scale, size=(1, number_individuals))\n",
    "        \n",
    "        # Update the index\n",
    "        k = k+1\n",
    "        \n",
    "    # Print the epoch and loss\n",
    "    print(f\"Epoch: {i}; loss: {np.mean(predicted_loss)}\")\n",
    "    \n",
    "# Print the predicted weights and bias\n",
    "print(\"\")\n",
    "print(f\"Predicted weights: {np.mean(predicted_weights, axis=1)}\")\n",
    "print(f\"Predicted bias: {np.mean(predicted_bias)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01.4.2. Learn the parameters of the neuron using a simpler evolutionary algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; loss: 14.065245619831437\n",
      "Epoch: 1; loss: 10.475700426308524\n",
      "Epoch: 2; loss: 7.542908621351353\n",
      "Epoch: 3; loss: 5.159025379365726\n",
      "Epoch: 4; loss: 3.122533523693872\n",
      "Epoch: 5; loss: 1.5003200038468014\n",
      "Epoch: 6; loss: 0.5791979401322016\n",
      "Epoch: 7; loss: 0.09645098729289182\n",
      "Epoch: 8; loss: 0.0001001751696473215\n",
      "Epoch: 9; loss: 7.551244142200755e-05\n",
      "\n",
      "Predicted weights: [ 2.00399397 -3.40051534]\n",
      "Predicted bias: [4.20423564]\n"
     ]
    }
   ],
   "source": [
    "# Define the training parameters\n",
    "number_epochs = 10\n",
    "batch_size = 10\n",
    "mutation_scale = 0.01\n",
    "\n",
    "# Initialize the predicted weights and bias\n",
    "predicted_weights = np.random.normal(loc=0.0, scale=0.01, size=number_features)\n",
    "predicted_bias = 0\n",
    "\n",
    "# Initialize the loss for all the batches\n",
    "number_batches = int(np.ceil(number_examples/batch_size))\n",
    "predicted_loss = np.zeros(number_batches)\n",
    "\n",
    "# Loop over the epochs\n",
    "for i in range(number_epochs):\n",
    "    \n",
    "    # Loop over the batches\n",
    "    k = 0\n",
    "    for j in range(0, number_examples, batch_size):\n",
    "        \n",
    "        # Derive the end index of the batch\n",
    "        j2 = min(j+batch_size, number_examples)\n",
    "    \n",
    "        # Compute the predicted outputs using the inputs, and the predicted weights and bias\n",
    "        predicted_outputs = np.matmul(true_inputs[j:j2, :], predicted_weights) + predicted_bias\n",
    "        \n",
    "        # Compute the loss using the mean squared error\n",
    "        predicted_loss[k] = np.mean(0.5*np.power(predicted_outputs-true_outputs[j:j2], 2))\n",
    "        \n",
    "        # Initialize the next loss\n",
    "        predicted_loss2 = np.inf                    \n",
    "        \n",
    "        # While the next predicted loss is higher\n",
    "        while predicted_loss2 >= predicted_loss[k]:\n",
    "            \n",
    "            # Mutate the weights and biases\n",
    "            predicted_weights2 = predicted_weights + np.random.normal(loc=0.0, scale=mutation_scale, size=number_features)\n",
    "            predicted_bias2 = predicted_bias + np.random.normal(loc=0.0, scale=mutation_scale, size=1)\n",
    "            \n",
    "            # Compute the new outputs and loss\n",
    "            predicted_outputs2 = np.matmul(true_inputs[j:j2, :], predicted_weights2) + predicted_bias2\n",
    "            predicted_loss2 = np.mean(0.5*np.power(predicted_outputs2-true_outputs[j:j2], 2))\n",
    "            \n",
    "        # Update the weights, biases, and loss\n",
    "        predicted_weights = predicted_weights2\n",
    "        predicted_bias = predicted_bias2\n",
    "        predicted_loss[k] = predicted_loss2\n",
    "        \n",
    "        # Update the index\n",
    "        k = k+1\n",
    "    \n",
    "    # Print the epoch and loss\n",
    "    print(f\"Epoch: {i}; loss: {np.mean(predicted_loss)}\")\n",
    "    \n",
    "# Print the predicted weights and bias\n",
    "print(\"\")\n",
    "print(f\"Predicted weights: {predicted_weights}\")\n",
    "print(f\"Predicted bias: {predicted_bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Single neuron and softmax regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.1. Prepare a dataset for a multiclass classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x720 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reset\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the fashion-MNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \\\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Show some of the data\n",
    "plt.figure(figsize=(17, 10))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.title(class_names[train_labels[i]])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "# Get the number of train and test examples and the sizes of the inputs and outputs\n",
    "number_train = np.shape(train_images)[0]\n",
    "number_test = np.shape(test_images)[0]\n",
    "input_size = np.shape(train_images)[1]*np.shape(train_images)[2]\n",
    "output_size = len(class_names)\n",
    "\n",
    "# Reshape the inputs and normalize them\n",
    "train_inputs = np.reshape(train_images, (number_train, input_size))\n",
    "train_inputs = train_inputs/255\n",
    "test_inputs = np.reshape(test_images, (number_test, input_size))\n",
    "test_inputs = test_inputs/255\n",
    "\n",
    "# Transform the outputs from label numbers to one-hot vectors\n",
    "train_outputs = np.zeros((number_train, output_size))\n",
    "for i in range(number_train):\n",
    "    train_outputs[i, train_labels[i]] = 1\n",
    "test_outputs = np.zeros((number_test, output_size))\n",
    "for i in range(number_test):\n",
    "    test_outputs[i, test_labels[i]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.2. Learn the parameters of a neuron using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; train loss: 0.7839464409853965; train accuracy: 0.7499058067375886; test accuracy: 0.1351\n",
      "Epoch: 1; train loss: 0.5700196939640748; train accuracy: 0.812638519503546; test accuracy: 0.7855\n",
      "Epoch: 2; train loss: 0.5250399792070662; train accuracy: 0.8255984042553192; test accuracy: 0.811\n",
      "Epoch: 3; train loss: 0.5009203389810575; train accuracy: 0.8316655585106383; test accuracy: 0.8194\n",
      "Epoch: 4; train loss: 0.485130030500342; train accuracy: 0.8365359042553191; test accuracy: 0.8244\n",
      "Epoch: 5; train loss: 0.47369480369247396; train accuracy: 0.84026484929078; test accuracy: 0.827\n",
      "Epoch: 6; train loss: 0.46489115482651205; train accuracy: 0.8426750886524822; test accuracy: 0.8289\n",
      "Epoch: 7; train loss: 0.4578281227460323; train accuracy: 0.844919104609929; test accuracy: 0.8323\n",
      "Epoch: 8; train loss: 0.4519897178943545; train accuracy: 0.8466145833333333; test accuracy: 0.8332\n",
      "Epoch: 9; train loss: 0.44705253709351034; train accuracy: 0.8478280141843971; test accuracy: 0.8343\n"
     ]
    }
   ],
   "source": [
    "# Define the training parameters\n",
    "number_epochs = 10\n",
    "batch_size = 256\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Initialize the weights and biases\n",
    "train_weights = np.random.normal(loc=0.0, scale=0.01, size=(input_size, output_size))\n",
    "train_biases = np.zeros(output_size)\n",
    "\n",
    "# Initialize the loss and the accuracy for all the batches\n",
    "number_batches = int(np.ceil(number_train/batch_size))\n",
    "train_loss = np.zeros(number_batches)\n",
    "train_accuracy = np.zeros(number_batches)\n",
    "\n",
    "# Loop over the epochs\n",
    "for i in range(number_epochs):\n",
    "    \n",
    "    # Compute the predicted test outputs using the test inputs, and the learned weights and biases\n",
    "    test_outputs2 = np.matmul(test_inputs, train_weights) + train_biases\n",
    "    \n",
    "    # Compute the conditional probabilities of each class using the softmax function\n",
    "    # (modified to avoid numerical stability issues)\n",
    "    test_outputs2 = test_outputs2-np.max(test_outputs2, axis=1)[:, np.newaxis]\n",
    "    test_exp = np.exp(test_outputs2)\n",
    "    test_softmax = test_exp/np.sum(test_exp, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Compute the classification accuracy given the true test labels\n",
    "    test_accuracy = np.mean(np.argmax(test_softmax, axis=1)==test_labels)\n",
    "    \n",
    "    # Loop over the batches\n",
    "    k = 0\n",
    "    for j in range(0, number_train, batch_size):\n",
    "        \n",
    "        # Derive the end index for the current batch\n",
    "        j2 = min(j+batch_size, number_train)\n",
    "    \n",
    "        # Compute the predicted train outputs using the train inputs, and the learned weights and biases\n",
    "        train_outputs2 = np.matmul(train_inputs[j:j2, :], train_weights) + train_biases\n",
    "        \n",
    "        # Compute the conditional probabilities of each class using the softmax function\n",
    "        # (modified to avoid numerical stability issues)\n",
    "        train_outputs2 = train_outputs2-np.max(train_outputs2, axis=1)[:, np.newaxis]\n",
    "        train_exp = np.exp(train_outputs2)\n",
    "        train_softmax = train_exp/np.sum(train_exp, axis=1)[:, np.newaxis]\n",
    "        \n",
    "        # Compute the cross-entropy loss given the true train outputs\n",
    "        # (rewritten to avoid numerical stability issues)\n",
    "#         train_loss[k] = np.mean(-np.sum(train_outputs[j:j2, :]*np.log(train_softmax), axis=1))\n",
    "        train_loss[k] = np.mean(-np.sum(train_outputs[j:j2, :]\\\n",
    "                                        *(train_outputs2-np.log(np.sum(train_exp, axis=1)[:, np.newaxis])), axis=1))\n",
    "        \n",
    "        # Compute the classification accuracy given the true train labels\n",
    "        train_accuracy[k] = np.mean(np.argmax(train_softmax, axis=1)==train_labels[j:j2])\n",
    "        \n",
    "        # Do not need to make the last updates after computing the last loss\n",
    "        if i < number_epochs-1 or k < number_batches-1:\n",
    "            \n",
    "            # Compute the derivative of the loss wrt the output (logit before softmax)\n",
    "            train_derivative = train_softmax-train_outputs[j:j2, :]\n",
    "            \n",
    "            # Get the real batch size\n",
    "            batch_size2 = j2-j\n",
    "            \n",
    "            # Update the weights and biases using gradient descent\n",
    "            train_weights = train_weights-learning_rate*np.matmul(train_inputs[j:j2, :].T, train_derivative)/batch_size2\n",
    "            train_biases = train_biases-learning_rate*np.sum(train_derivative, axis=0)/batch_size2\n",
    "            \n",
    "        # Update the index\n",
    "        k = k+1\n",
    "        \n",
    "    # Print the epoch and loss\n",
    "    print(f\"Epoch: {i}; train loss: {np.mean(train_loss)}; train accuracy: {np.mean(train_accuracy)}; test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.3. Make predictions using the trained neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x720 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the predicted test outputs using the test inputs, and the learned weights and biases\n",
    "test_outputs2 = np.matmul(test_inputs, train_weights) + train_biases\n",
    "\n",
    "# Compute the conditional probabilities of each class using the softmax function\n",
    "# (modified to avoid numerical stability issues)\n",
    "test_outputs2 = test_outputs2-np.max(test_outputs2, axis=1)[:, np.newaxis]\n",
    "test_exp = np.exp(test_outputs2)\n",
    "test_softmax = test_exp/np.sum(test_exp, axis=1)[:, np.newaxis]\n",
    "\n",
    "# Compute the predicted labels\n",
    "test_labels2 = np.argmax(test_softmax, axis=1)\n",
    "\n",
    "# Show the data with the true and predicted labels\n",
    "plt.figure(figsize=(17, 10))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(test_images[i], cmap=plt.cm.binary)\n",
    "    plt.title(class_names[test_labels[i]] + \"\\n\" + class_names[test_labels2[i]])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.4. Learn the parameters of a neuron using gradient descent in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 [==============================] - 0s 786us/step - loss: 1.0260 - accuracy: 0.6745\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 0s 778us/step - loss: 0.5864 - accuracy: 0.8079\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 0s 765us/step - loss: 0.5351 - accuracy: 0.8228\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 0s 782us/step - loss: 0.5028 - accuracy: 0.8317\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 0s 799us/step - loss: 0.4893 - accuracy: 0.8365\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 0s 774us/step - loss: 0.4764 - accuracy: 0.8387\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 0s 782us/step - loss: 0.4682 - accuracy: 0.8408\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 0s 821us/step - loss: 0.4630 - accuracy: 0.8431\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 0s 765us/step - loss: 0.4537 - accuracy: 0.8467\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 0s 765us/step - loss: 0.4402 - accuracy: 0.8507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fdd3c56bb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the training parameters\n",
    "number_epochs = 10\n",
    "batch_size = 256\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Initialize the model (as a feedforward NN)\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add an input with the number of features\n",
    "model.add(tf.keras.Input(shape=input_size))\n",
    "\n",
    "# Add a densely-connected NN layer without activation and with initialized weights and bias\n",
    "model.add(tf.keras.layers.Dense(output_size, activation=None, \\\n",
    "                                kernel_initializer=tf.initializers.RandomNormal(mean=0, stddev=0.01), \\\n",
    "                                bias_initializer=\"zeros\"))\n",
    "\n",
    "# Configure the model for training with gradient descent optimizer and cross-entropy loss\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate), \\\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \\\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model give the batch size and number of epochs\n",
    "model.fit(x=train_inputs, y=train_outputs, batch_size=batch_size, epochs=number_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.5. Learn the parameters of a neuron using an EA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; train loss: 1.4465094193881702; train accuracy: 0.5345279255319149; test accuracy: 0.07\n",
      "Epoch: 1; train loss: 0.9218235883082819; train accuracy: 0.6845528590425531; test accuracy: 0.644\n",
      "Epoch: 2; train loss: 0.8139263195166209; train accuracy: 0.7183649157801419; test accuracy: 0.7024\n",
      "Epoch: 3; train loss: 0.760241497606201; train accuracy: 0.7354892508865248; test accuracy: 0.7257\n",
      "Epoch: 4; train loss: 0.7459400614672582; train accuracy: 0.739726285460993; test accuracy: 0.7304\n",
      "Epoch: 5; train loss: 0.7301011253673003; train accuracy: 0.7481776374113476; test accuracy: 0.7404\n",
      "Epoch: 6; train loss: 0.7234255716094935; train accuracy: 0.752698359929078; test accuracy: 0.7444\n",
      "Epoch: 7; train loss: 0.7211583417899639; train accuracy: 0.7531155806737588; test accuracy: 0.7407\n",
      "Epoch: 8; train loss: 0.7126968935196831; train accuracy: 0.757130429964539; test accuracy: 0.749\n",
      "Epoch: 9; train loss: 0.6986442258115251; train accuracy: 0.763071254432624; test accuracy: 0.7504\n"
     ]
    }
   ],
   "source": [
    "# Define the training parameters\n",
    "number_epochs = 10\n",
    "batch_size = 256\n",
    "number_individuals = 10\n",
    "number_parents = 2\n",
    "mutation_rate = 0.01\n",
    "\n",
    "# Initialize the weights and biases for all the individuals\n",
    "train_weights = np.random.normal(loc=0.0, scale=0.01, size=(input_size, output_size, number_individuals))\n",
    "train_biases = np.zeros((output_size, number_individuals))\n",
    "\n",
    "# Initialize the loss and the accuracy for all the batches and for all the individuals\n",
    "number_batches = int(np.ceil(number_train/batch_size))\n",
    "train_loss = np.zeros((number_batches, number_individuals))\n",
    "train_accuracy = np.zeros((number_batches, number_individuals))\n",
    "\n",
    "# Loop over the epochs\n",
    "for i in range(number_epochs):\n",
    "    \n",
    "    # Compute the predicted test outputs using the test inputs, and the learned weights and biases\n",
    "    test_outputs2 = np.matmul(test_inputs, np.mean(train_weights, axis=2)) + np.mean(train_biases, axis=1)[np.newaxis, :]\n",
    "    \n",
    "    # Compute the conditional probabilities of each class using the softmax function\n",
    "    # (modified to avoid numerical stability issues)\n",
    "    test_outputs2 = test_outputs2-np.max(test_outputs2, axis=1)[:, np.newaxis]\n",
    "    test_exp = np.exp(test_outputs2)\n",
    "    test_softmax = test_exp/np.sum(test_exp, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Compute the classification accuracy given the true test labels\n",
    "    test_accuracy = np.mean(np.argmax(test_softmax, axis=1)==test_labels)\n",
    "    \n",
    "    # Loop over the batches\n",
    "    k = 0\n",
    "    for j in range(0, number_train, batch_size):\n",
    "        \n",
    "        # Derive the end index for the current batch\n",
    "        j2 = min(j+batch_size, number_train)\n",
    "    \n",
    "        # Compute the predicted train outputs using the train inputs, and the learned weights and biases, for every individual\n",
    "        train_outputs2 = np.tensordot(train_inputs[j:j2, :], train_weights, axes=(1,0)) + train_biases[np.newaxis, :, :]\n",
    "        \n",
    "        # Compute the conditional probabilities of each class using the softmax function\n",
    "        # (modified to avoid numerical stability issues)\n",
    "        train_outputs2 = train_outputs2-np.max(train_outputs2, axis=1)[:, np.newaxis, :]\n",
    "        train_exp = np.exp(train_outputs2)\n",
    "        train_softmax = train_exp/np.sum(train_exp, axis=1)[:, np.newaxis, :]\n",
    "        \n",
    "        # Compute the cross-entropy loss given the true train outputs\n",
    "        # (rewritten to avoid numerical stability issues)\n",
    "#         train_loss[k] = np.mean(-np.sum(train_outputs[j:j2, :, np.newaxis]*np.log(train_softmax), axis=1), axis=0)\n",
    "        train_loss[k, :] = np.mean(-np.sum(train_outputs[j:j2, :, np.newaxis]\\\n",
    "                                        *(train_outputs2-np.log(np.sum(train_exp, axis=1)[:, np.newaxis, :])), axis=1), axis=0)\n",
    "        \n",
    "        # Compute the classification accuracy given the true train labels\n",
    "        train_accuracy[k, :] = np.mean(np.argmax(train_softmax, axis=1) == train_labels[j:j2, np.newaxis], axis=0)\n",
    "        \n",
    "        # Do not need to make the last updates after computing the last loss\n",
    "        if i < number_epochs-1 or k < number_batches-1:\n",
    "            \n",
    "            # Get the indices of the parents (the fittest individuals)\n",
    "            parent_indices = np.argsort(train_loss[k, :])[0:number_parents]\n",
    "\n",
    "            # Compute the mutation scale using the root mean square error\n",
    "#             mutation_scale = 0.001*np.mean(np.sqrt(train_loss[k, parent_indices]))\n",
    "            mutation_scale = mutation_rate\n",
    "            \n",
    "            # Update the weights and bias using EA, doing crossover and mutation\n",
    "            train_weights = np.mean(train_weights[:, :, parent_indices], axis=2)[:, :, np.newaxis] \\\n",
    "            + np.random.normal(loc=0.0, scale=mutation_scale, size=(input_size, output_size, number_individuals))\n",
    "            train_biases = np.mean(train_biases[:, parent_indices], axis=1)[:, np.newaxis] \\\n",
    "            + np.random.normal(loc=0.0, scale=mutation_scale, size=(output_size, number_individuals))\n",
    "            \n",
    "        # Update the index\n",
    "        k = k+1\n",
    "        \n",
    "    # Print the epoch and loss\n",
    "    print(f\"Epoch: {i}; train loss: {np.mean(train_loss)}; train accuracy: {np.mean(train_accuracy)}; test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.5.2. Learn the parameters of a neuron using a simpler EA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; train loss: 1.621563828515087; train accuracy: 0.4235316932624113; test accuracy: 0.104\n",
      "Epoch: 1; train loss: 1.1440197808068515; train accuracy: 0.5999390514184396; test accuracy: 0.5395\n",
      "Epoch: 2; train loss: 1.0125098480022172; train accuracy: 0.6448692375886524; test accuracy: 0.6223\n",
      "Epoch: 3; train loss: 0.9454505312722947; train accuracy: 0.6734042553191489; test accuracy: 0.6549\n",
      "Epoch: 4; train loss: 0.9261953723244406; train accuracy: 0.6887743794326242; test accuracy: 0.6722\n",
      "Epoch: 5; train loss: 0.9192104357721197; train accuracy: 0.6963874113475178; test accuracy: 0.6851\n",
      "Epoch: 6; train loss: 0.9384921693477174; train accuracy: 0.6914782801418439; test accuracy: 0.6755\n",
      "Epoch: 7; train loss: 0.9645869029679914; train accuracy: 0.6906083776595745; test accuracy: 0.6756\n",
      "Epoch: 8; train loss: 0.9776656155766568; train accuracy: 0.6948027482269503; test accuracy: 0.6868\n",
      "Epoch: 9; train loss: 0.998035759001683; train accuracy: 0.6964206560283689; test accuracy: 0.6819\n"
     ]
    }
   ],
   "source": [
    "# Define the training parameters\n",
    "number_epochs = 10\n",
    "batch_size = 256\n",
    "mutation_scale = 0.01\n",
    "\n",
    "# Initialize the weights and biases\n",
    "train_weights = np.random.normal(loc=0.0, scale=0.01, size=(input_size, output_size))\n",
    "train_biases = np.zeros(output_size)\n",
    "\n",
    "# Initialize the loss and the accuracy for all the batches\n",
    "number_batches = int(np.ceil(number_train/batch_size))\n",
    "train_loss = np.zeros(number_batches)\n",
    "train_accuracy = np.zeros(number_batches)\n",
    "\n",
    "# Loop over the epochs\n",
    "for i in range(number_epochs):\n",
    "    \n",
    "    # Compute the predicted test outputs using the test inputs, and the learned weights and biases\n",
    "    test_outputs2 = np.matmul(test_inputs, train_weights) + train_biases\n",
    "    \n",
    "    # Compute the conditional probabilities of each class using the softmax function\n",
    "    # (modified to avoid numerical stability issues)\n",
    "    test_outputs2 = test_outputs2-np.max(test_outputs2, axis=1)[:, np.newaxis]\n",
    "    test_exp = np.exp(test_outputs2)\n",
    "    test_softmax = test_exp/np.sum(test_exp, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Compute the classification accuracy given the true test labels\n",
    "    test_accuracy = np.mean(np.argmax(test_softmax, axis=1)==test_labels)\n",
    "    \n",
    "    # Loop over the batches\n",
    "    k = 0\n",
    "    for j in range(0, number_train, batch_size):\n",
    "        \n",
    "        # Derive the end index for the current batch\n",
    "        j2 = min(j+batch_size, number_train)\n",
    "    \n",
    "        # Compute the predicted train outputs using the train inputs, and the learned weights and biases\n",
    "        train_outputs2 = np.matmul(train_inputs[j:j2, :], train_weights) + train_biases\n",
    "        \n",
    "        # Compute the conditional probabilities of each class using the softmax function\n",
    "        # (modified to avoid numerical stability issues)\n",
    "        train_outputs2 = train_outputs2-np.max(train_outputs2, axis=1)[:, np.newaxis]\n",
    "        train_exp = np.exp(train_outputs2)\n",
    "        train_softmax = train_exp/np.sum(train_exp, axis=1)[:, np.newaxis]\n",
    "        \n",
    "        # Compute the cross-entropy loss given the true train outputs\n",
    "        # (rewritten to avoid numerical stability issues)\n",
    "#         train_loss[k] = np.mean(-np.sum(train_outputs[j:j2, :]*np.log(train_softmax), axis=1))\n",
    "        train_loss[k] = np.mean(-np.sum(train_outputs[j:j2, :]\\\n",
    "                                        *(train_outputs2-np.log(np.sum(train_exp, axis=1)[:, np.newaxis])), axis=1))\n",
    "        \n",
    "        # Compute the classification accuracy given the true train labels\n",
    "        train_accuracy[k] = np.mean(np.argmax(train_softmax, axis=1)==train_labels[j:j2])\n",
    "        \n",
    "        # Do not need to make the last updates after computing the last loss\n",
    "        if i < number_epochs-1 or k < number_batches-1:\n",
    "            \n",
    "            # Initialize the next loss\n",
    "            train_loss2 = np.inf\n",
    "#             train_accuracy2 = -np.inf\n",
    "            \n",
    "            # While the next loss is higher\n",
    "            while train_loss2 >= train_loss[k]:# or train_accuracy2 <= train_accuracy[k]:\n",
    "                \n",
    "                # Mutate the weights and biases\n",
    "                train_weights2 = train_weights + np.random.normal(loc=0.0, scale=mutation_scale, size=(input_size, output_size))\n",
    "                train_biases2 = train_biases + np.random.normal(loc=0.0, scale=mutation_scale, size=output_size)\n",
    "\n",
    "                # Compute the new outputs and loss\n",
    "                train_outputs2 = np.matmul(train_inputs[j:j2, :], train_weights2) + train_biases2\n",
    "                train_outputs2 = train_outputs2-np.max(train_outputs2, axis=1)[:, np.newaxis]\n",
    "                train_exp = np.exp(train_outputs2)\n",
    "                train_softmax = train_exp/np.sum(train_exp, axis=1)[:, np.newaxis]\n",
    "                train_loss2 = np.mean(-np.sum(train_outputs[j:j2, :]\n",
    "                                              *(train_outputs2-np.log(np.sum(train_exp, axis=1)[:, np.newaxis])), axis=1))\n",
    "                train_accuracy2 = np.mean(np.argmax(train_softmax, axis=1)==train_labels[j:j2])\n",
    "                \n",
    "            # Update the weights, biases, and loss\n",
    "            train_weights = train_weights2\n",
    "            train_biases = train_biases2\n",
    "#             train_weights = train_weights+(train_weights2-train_weights)\n",
    "#             train_biases = train_biases+(train_biases2-train_biases)\n",
    "            train_loss[k] = train_loss2\n",
    "            train_accuracy[k] = train_accuracy2\n",
    "            \n",
    "        # Update the index\n",
    "        k = k+1\n",
    "        \n",
    "    # Print the epoch and loss\n",
    "    print(f\"Epoch: {i}; train loss: {np.mean(train_loss)}; train accuracy: {np.mean(train_accuracy)}; test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training parameters\n",
    "number_epochs = 10\n",
    "batch_size = 256\n",
    "mutation_scale = 1\n",
    "\n",
    "# Initialize the weights and biases\n",
    "train_weights = np.random.normal(loc=0.0, scale=0.01, size=(input_size, output_size, 2))\n",
    "train_biases = np.random.normal(loc=0.0, scale=0.01, size=(output_size, 2))\n",
    "\n",
    "# Initialize the loss and the accuracy for all the batches\n",
    "number_batches = int(np.ceil(number_train/batch_size))\n",
    "train_loss = np.zeros(number_batches)\n",
    "train_accuracy = np.zeros(number_batches)\n",
    "\n",
    "# Loop over the epochs\n",
    "k = 0\n",
    "for i in range(number_epochs):\n",
    "    \n",
    "    # Compute the predicted test outputs using the test inputs, and the learned weights and biases\n",
    "    test_outputs2 = np.matmul(test_inputs, train_weights[:, :, 1]) + train_biases[:, 1]\n",
    "    \n",
    "    # Compute the conditional probabilities of each class using the softmax function\n",
    "    # (modified to avoid numerical stability issues)\n",
    "    test_outputs2 = test_outputs2-np.max(test_outputs2, axis=1)[:, np.newaxis]\n",
    "    test_exp = np.exp(test_outputs2)\n",
    "    test_softmax = test_exp/np.sum(test_exp, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Compute the classification accuracy given the true test labels\n",
    "    test_accuracy = np.mean(np.argmax(test_softmax, axis=1)==test_labels)\n",
    "    \n",
    "    # Loop over the batches\n",
    "    k = 0\n",
    "    for j in range(0, number_train, batch_size):\n",
    "        \n",
    "        # Derive the end index for the current batch\n",
    "        j2 = min(j+batch_size, number_train)\n",
    "    \n",
    "        # Compute the predicted train outputs using the train inputs, and the learned weights and biases\n",
    "        train_outputs2 = np.matmul(train_inputs[j:j2, :], train_weights[:, :, 1]) + train_biases[:, 1]\n",
    "        \n",
    "        # Compute the conditional probabilities of each class using the softmax function\n",
    "        # (modified to avoid numerical stability issues)\n",
    "        train_outputs2 = train_outputs2-np.max(train_outputs2, axis=1)[:, np.newaxis]\n",
    "        train_exp = np.exp(train_outputs2)\n",
    "        train_softmax = train_exp/np.sum(train_exp, axis=1)[:, np.newaxis]\n",
    "        \n",
    "        # Compute the cross-entropy loss given the true train outputs\n",
    "        # (rewritten to avoid numerical stability issues)\n",
    "#         train_loss[k] = np.mean(-np.sum(train_outputs[j:j2, :]*np.log(train_softmax), axis=1))\n",
    "        train_loss[k] = np.mean(-np.sum(train_outputs[j:j2, :]\\\n",
    "                                        *(train_outputs2-np.log(np.sum(train_exp, axis=1)[:, np.newaxis])), axis=1))\n",
    "        \n",
    "        # Compute the classification accuracy given the true train labels\n",
    "        train_accuracy[k] = np.mean(np.argmax(train_softmax, axis=1)==train_labels[j:j2])\n",
    "        \n",
    "        # Do not need to make the last updates after computing the last loss\n",
    "        if i < number_epochs-1 or k < number_batches-1:\n",
    "            \n",
    "            # Initialize the next loss\n",
    "            train_loss2 = np.inf\n",
    "            \n",
    "            # While the next loss is higher\n",
    "            while train_loss2 >= train_loss[k]:\n",
    "                \n",
    "                # Mutate the weights and biases\n",
    "                train_weights2 = train_weights[:, :, 1] - (train_weights[:, :, 1]-train_weights[:, :, 0])*np.random.normal(loc=0, scale=mutation_scale, size=(input_size, output_size))\n",
    "                train_biases2 = train_biases[:, 1] - (train_biases[:, 1]-train_biases[:, 0])*np.random.normal(loc=0, scale=mutation_scale, size=output_size)\n",
    "                                \n",
    "                # Compute the new outputs and loss\n",
    "                train_outputs2 = np.matmul(train_inputs[j:j2, :], train_weights2) + train_biases2\n",
    "                train_outputs2 = train_outputs2-np.max(train_outputs2, axis=1)[:, np.newaxis]\n",
    "                train_exp = np.exp(train_outputs2)\n",
    "                train_softmax = train_exp/np.sum(train_exp, axis=1)[:, np.newaxis]\n",
    "                train_loss2 = np.mean(-np.sum(train_outputs[j:j2, :]\n",
    "                                              *(train_outputs2-np.log(np.sum(train_exp, axis=1)[:, np.newaxis])), axis=1))\n",
    "                train_accuracy2 = np.mean(np.argmax(train_softmax, axis=1)==train_labels[j:j2])\n",
    "                \n",
    "            # Update the weights, biases, and loss\n",
    "            train_weights[:, :, 1] = train_weights2\n",
    "            train_biases[:, 1] = train_biases2\n",
    "            train_loss[k] = train_loss2\n",
    "            train_accuracy[k] = train_accuracy2\n",
    "            \n",
    "            train_weights[:, :, 0] = train_weights2\n",
    "            train_biases[:, 0] = train_biases2\n",
    "            \n",
    "        # Update the index\n",
    "        k = k+1\n",
    "        \n",
    "    # Print the epoch and loss\n",
    "    print(f\"Epoch: {i}; train loss: {np.mean(train_loss)}; train accuracy: {np.mean(train_accuracy)}; test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Multilayer Perceptrons (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.1. Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import the fashion-MNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \\\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Get the number of train and test examples and the sizes of the inputs and outputs\n",
    "number_train = np.shape(train_images)[0]\n",
    "number_test = np.shape(test_images)[0]\n",
    "input_size = np.shape(train_images)[1]*np.shape(train_images)[2]\n",
    "output_size = len(class_names)\n",
    "\n",
    "# Reshape the inputs and normalize them\n",
    "train_inputs = np.reshape(train_images, (number_train, input_size))\n",
    "train_inputs = train_inputs/255\n",
    "test_inputs = np.reshape(test_images, (number_test, input_size))\n",
    "test_inputs = test_inputs/255\n",
    "\n",
    "# Transform the outputs from label numbers to one-hot vectors\n",
    "train_outputs = np.zeros((number_train, output_size))\n",
    "for i in range(number_train):\n",
    "    train_outputs[i, train_labels[i]] = 1\n",
    "test_outputs = np.zeros((number_test, output_size))\n",
    "for i in range(number_test):\n",
    "    test_outputs[i, test_labels[i]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.2. Implement MLP from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.105174919420924e-05\n",
      "6.206998985014409e-05\n",
      "6.940576560457169e-05\n",
      "6.321401717197057e-05\n",
      "6.924309378080666e-05\n",
      "6.493339956437433e-05\n",
      "7.378756407600092e-05\n",
      "6.851322568165091e-05\n",
      "7.840098632161467e-05\n",
      "7.290204040807286e-05\n",
      "7.723810378023638e-05\n",
      "8.102146950572028e-05\n",
      "8.315632092829314e-05\n",
      "8.808895142602243e-05\n",
      "0.00010163929890935798\n",
      "9.640105763268237e-05\n",
      "0.00010035039725381715\n",
      "0.00010867259554261896\n",
      "0.00011059092998856451\n",
      "0.00011040311935071905\n",
      "0.00010843198264111418\n",
      "0.0001063385124656663\n",
      "0.00011779686567740004\n",
      "0.00011640827712703204\n",
      "0.00012042507533549038\n",
      "0.00011343752012025193\n",
      "0.0001285963099140055\n",
      "0.00012799235970337023\n",
      "0.00012355470904699037\n",
      "0.00011847320643191974\n",
      "0.00011898448685944993\n",
      "0.0001160285797006538\n",
      "0.00012595011838683606\n",
      "0.00011744745803800825\n",
      "0.00010585776205430478\n",
      "0.00010479149630394456\n",
      "0.00010822449824156912\n",
      "0.0001034368113796774\n",
      "9.995506266919286e-05\n",
      "0.00010537496975974\n",
      "9.421998578868676e-05\n",
      "0.00010102816076585081\n",
      "0.00011134360953780143\n",
      "9.8251242324383e-05\n",
      "0.00010149752796154524\n",
      "9.246766459946716e-05\n",
      "0.00010218156569297464\n",
      "9.3638125236314e-05\n",
      "8.895506490470752e-05\n",
      "9.2056141875729e-05\n",
      "9.693833640098245e-05\n",
      "8.244014105691204e-05\n",
      "9.522046477262448e-05\n",
      "9.261057993004403e-05\n",
      "7.601143774459327e-05\n",
      "8.23535967765571e-05\n",
      "8.004744474157854e-05\n",
      "9.064239385545775e-05\n",
      "8.520528127602414e-05\n",
      "8.560714392142738e-05\n",
      "8.017569302248007e-05\n",
      "7.852955928741375e-05\n",
      "0.0001060534217878179\n",
      "9.074547417264051e-05\n",
      "7.835014378696624e-05\n",
      "7.2080125908287e-05\n",
      "9.609796847092895e-05\n",
      "6.584314964990718e-05\n",
      "8.48735262666827e-05\n",
      "7.115910730688224e-05\n",
      "8.780716912544621e-05\n",
      "7.886042552507981e-05\n",
      "8.131886141243908e-05\n",
      "9.164256535707934e-05\n",
      "7.886241720358561e-05\n",
      "6.265393115876583e-05\n",
      "8.599106098850183e-05\n",
      "7.098827992369997e-05\n",
      "6.702304127911779e-05\n",
      "6.878328451761729e-05\n",
      "7.845312344349806e-05\n",
      "7.395081103398816e-05\n",
      "0.00010103256375945527\n",
      "7.297706352710512e-05\n",
      "8.522739117313596e-05\n",
      "8.50426643872194e-05\n",
      "0.00012242057676191002\n",
      "0.00010661188654233135\n",
      "0.00011707934345409131\n",
      "9.762361335710994e-05\n",
      "5.903923340588088e-05\n",
      "0.00011866778944708375\n",
      "9.299429055477806e-05\n",
      "7.709286810363118e-05\n",
      "7.127435798760466e-05\n",
      "8.527737340229708e-05\n",
      "9.143537207247222e-05\n",
      "6.950768658639966e-05\n",
      "6.498273983267538e-05\n",
      "9.162662864092791e-05\n",
      "6.681646217459225e-05\n",
      "7.900857466522345e-05\n",
      "9.20337239101582e-05\n",
      "0.00012596240738412117\n",
      "8.90077484181488e-05\n",
      "5.631846162217265e-05\n",
      "6.254984357641593e-05\n",
      "6.666350987739354e-05\n",
      "0.00010908996199146687\n",
      "0.00012459785162085443\n",
      "9.0139301375048e-05\n",
      "8.410462469236729e-05\n",
      "9.794829140975236e-05\n",
      "8.481786527642718e-05\n",
      "9.698096609121925e-05\n",
      "0.00010089850191774177\n",
      "7.879852107308073e-05\n",
      "7.1756499866977e-05\n",
      "7.409954495059363e-05\n",
      "6.897976247348773e-05\n",
      "9.279204851956464e-05\n",
      "9.160631466081022e-05\n",
      "9.03881224355639e-05\n",
      "6.004061568451473e-05\n",
      "6.902739034155398e-05\n",
      "7.717709063749947e-05\n",
      "8.378106581014011e-05\n",
      "8.938704717002993e-05\n",
      "7.319678803748792e-05\n",
      "6.202794910281371e-05\n",
      "7.931792297300743e-05\n",
      "0.00011221805530077038\n",
      "7.024976915068762e-05\n",
      "0.00014558347472504702\n",
      "9.466609803235843e-05\n",
      "9.5698208093921e-05\n",
      "0.00011674793110201138\n",
      "0.00013507080172985435\n",
      "6.288453520069743e-05\n",
      "5.518295814285246e-05\n",
      "5.3298284899750374e-05\n",
      "6.276959660132715e-05\n",
      "9.116878597273933e-05\n",
      "9.503056236590663e-05\n",
      "9.135029410341449e-05\n",
      "5.4347819529935396e-05\n",
      "7.233112164291012e-05\n",
      "6.8553157066317e-05\n",
      "9.315433995485497e-05\n",
      "6.751223567834358e-05\n",
      "7.369423653333048e-05\n",
      "7.95520047824173e-05\n",
      "5.972485740773761e-05\n",
      "7.177267389324008e-05\n",
      "8.035573835713197e-05\n",
      "8.229764105731142e-05\n",
      "9.917024858021924e-05\n",
      "9.921084527794655e-05\n",
      "9.604185689889418e-05\n",
      "9.679037057880591e-05\n",
      "0.00010037801053797268\n",
      "7.608317595779396e-05\n",
      "0.00012176357223769617\n",
      "7.154286146412488e-05\n",
      "8.69705363506528e-05\n",
      "8.56007635377966e-05\n",
      "9.59260442082771e-05\n",
      "0.00010890733519258722\n",
      "0.00016177319337918564\n",
      "0.00016472017174577722\n",
      "8.046498356634048e-05\n",
      "0.00011589029906451392\n",
      "9.050708725821046e-05\n",
      "0.0001314926798481589\n",
      "6.587278219704385e-05\n",
      "6.287369413416405e-05\n",
      "0.00010700897671773396\n",
      "0.00010072619187539456\n",
      "7.253471913866502e-05\n",
      "7.653013635503574e-05\n",
      "7.932509019570194e-05\n",
      "7.656234451839453e-05\n",
      "7.154663840730141e-05\n",
      "0.00010184548429518293\n",
      "8.861874305862893e-05\n",
      "7.845593091814907e-05\n",
      "7.79904851217621e-05\n",
      "5.4893924531587346e-05\n",
      "8.943759228232199e-05\n",
      "7.717008469985697e-05\n",
      "9.329106045507312e-05\n",
      "9.328277961767087e-05\n",
      "7.638736928627137e-05\n",
      "0.00010208273464873356\n",
      "9.73890482920193e-05\n",
      "0.000105376667249615\n",
      "9.197100622027263e-05\n",
      "7.653679116212125e-05\n",
      "9.803933789586858e-05\n",
      "0.00013416103902105916\n",
      "0.00012137836506651184\n",
      "5.174589839340368e-05\n",
      "8.161761113631034e-05\n",
      "7.222823870669365e-05\n",
      "9.275440896208451e-05\n",
      "0.0001129431350018619\n",
      "8.87612181282523e-05\n",
      "0.00011060392831366654\n",
      "9.176727970216283e-05\n",
      "8.657785213173108e-05\n",
      "0.0001043104520984873\n",
      "0.00012076766222806696\n",
      "0.0001034365710354098\n",
      "7.995408716354239e-05\n",
      "0.00011547377677945797\n",
      "0.00013701859933971767\n",
      "0.00015874702730507562\n",
      "0.00010668395490226691\n",
      "0.00012343546586736118\n",
      "0.00014090717178259491\n",
      "9.276508025392381e-05\n",
      "7.139554531868786e-05\n",
      "8.741321102967556e-05\n",
      "7.8022100499126e-05\n",
      "7.672537116387728e-05\n",
      "8.814010289649422e-05\n",
      "7.965067964377152e-05\n",
      "8.282493759874031e-05\n",
      "8.11461637121174e-05\n",
      "8.039851026656172e-05\n",
      "0.00013454565945920208\n",
      "9.431017301388181e-05\n",
      "0.00022215976561350013\n",
      "0.0002373630614425895\n",
      "0.00025368021953487086\n",
      "Epoch: 0; train loss: 1.060044262420009; train accuracy: 0.643855274822695; test accuracy: 0.1194\n",
      "0.00017867958684205873\n",
      "8.548711277696338e-05\n",
      "7.187936049822302e-05\n",
      "0.000142317835476511\n",
      "0.00017959609410697416\n",
      "0.00010675045235844655\n",
      "5.320940921779562e-05\n",
      "8.936406451905628e-05\n",
      "8.368921407327872e-05\n",
      "0.00011232074372539505\n",
      "0.00011483981957950744\n",
      "8.07095690061802e-05\n",
      "9.53360708887694e-05\n",
      "0.0001036434967532398\n",
      "0.0001697254962672049\n",
      "9.698795121420496e-05\n",
      "9.622437431703834e-05\n",
      "7.91929548211529e-05\n",
      "9.358601488134446e-05\n",
      "8.3159835587669e-05\n",
      "6.886365260190704e-05\n",
      "7.891191493702724e-05\n",
      "0.0001103895587217111\n",
      "9.710845344602916e-05\n",
      "8.910143368574145e-05\n",
      "0.0001696739111198374\n",
      "0.00018596592857331794\n",
      "0.0001495348214942663\n",
      "0.0001322024163238267\n",
      "0.00020316943595078126\n",
      "0.0001284045086396636\n",
      "7.271159496022763e-05\n",
      "0.00021979169761874234\n",
      "0.000238416171995387\n",
      "0.00016402090212869818\n",
      "0.00012134361609715285\n",
      "0.00010312900151501093\n",
      "0.0001451728062150011\n",
      "0.00014201963571194054\n",
      "8.42004741273641e-05\n",
      "0.00013499725291380598\n",
      "7.885694174138543e-05\n",
      "9.205956744889197e-05\n",
      "0.00011900901371475047\n",
      "0.0001259662844618216\n",
      "0.00010492303084241811\n",
      "0.00011064746519943479\n",
      "0.0001390165413558539\n",
      "7.635532115197305e-05\n",
      "9.980686782430757e-05\n",
      "9.513599205396386e-05\n",
      "0.00011791054987981172\n",
      "9.39653952758972e-05\n",
      "0.00010856319815733245\n",
      "7.905800863679867e-05\n",
      "7.874210119726567e-05\n",
      "0.00013747314412237367\n",
      "0.00019529705801392554\n",
      "0.00017994256030483163\n",
      "6.397377206628928e-05\n",
      "0.00010130258520809092\n",
      "0.00010152185318338758\n",
      "9.675568513393006e-05\n",
      "0.0001312417804507538\n",
      "8.19572912380834e-05\n",
      "8.036329856034975e-05\n",
      "0.00011935049769719155\n",
      "8.555873803261839e-05\n",
      "9.178486207483947e-05\n",
      "7.759763135616038e-05\n",
      "8.575058430524646e-05\n",
      "7.474937207026645e-05\n",
      "0.00014734634560277304\n",
      "0.00015466454889878373\n",
      "9.181065818705506e-05\n",
      "7.753938223338914e-05\n",
      "0.00012089212274718016\n",
      "0.0001595453537732405\n",
      "0.00010543760339498862\n",
      "9.326254806146866e-05\n",
      "9.75803379831661e-05\n",
      "6.836222329586783e-05\n",
      "0.00012210994121213223\n",
      "0.00011245197781445955\n",
      "0.00013917667264991336\n",
      "0.0001482162028166296\n",
      "0.00019178098309797795\n",
      "0.00012567154280037872\n",
      "0.00013245882404727607\n",
      "0.00011734179387675566\n",
      "7.231202196642736e-05\n",
      "0.00023935842763896575\n",
      "0.0003074551632619051\n",
      "0.00014572271485636755\n",
      "9.676980959646431e-05\n",
      "9.64428951625053e-05\n",
      "0.00012962326915275015\n",
      "0.00012024511738854036\n",
      "6.984826268793911e-05\n",
      "0.00013031786002823674\n",
      "6.946745853165908e-05\n",
      "0.00010797166567648899\n",
      "0.0001291586754816749\n",
      "0.00020977744917888207\n",
      "0.0002506801407051701\n",
      "0.00018064598045755998\n",
      "0.00012919344381408547\n",
      "0.00010930041076393551\n",
      "0.0001736467386562665\n",
      "0.0001849690740454722\n",
      "0.000127809672712378\n",
      "0.00012645426431870502\n",
      "0.0001276225533678747\n",
      "9.643151005176657e-05\n",
      "0.0001458744864139526\n",
      "0.00019518656580092092\n",
      "9.635207325137258e-05\n",
      "0.00011397017484666786\n",
      "0.00011404279977527056\n",
      "8.342619868779401e-05\n",
      "0.0001540478069732929\n",
      "0.00018689049749728905\n",
      "0.0001266183092005802\n",
      "6.220109687973586e-05\n",
      "9.541613810848416e-05\n",
      "0.0001289946124517678\n",
      "7.43176109807173e-05\n",
      "0.0001408877800112581\n",
      "0.00016367056474444653\n",
      "9.00210618842627e-05\n",
      "0.00015590590187261806\n",
      "0.0001608256964011204\n",
      "7.092011871718606e-05\n",
      "0.00019465860603892117\n",
      "0.00016514433213561498\n",
      "0.00014115538596645504\n",
      "0.00018232922599169208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00016340101321072183\n",
      "8.198891739027833e-05\n",
      "8.29604904479883e-05\n",
      "7.677555311593059e-05\n",
      "7.178457799642126e-05\n",
      "0.00014029274855487198\n",
      "0.00018538256309399973\n",
      "0.00014612364706950834\n",
      "0.0001079695558072201\n",
      "0.00011710180933596378\n",
      "0.00013324193446476756\n",
      "0.0001723164505123411\n",
      "0.0001090569254077235\n",
      "0.00010328882771671147\n",
      "0.00010559546344884463\n",
      "9.45749358213873e-05\n",
      "9.544722290016365e-05\n",
      "0.00012052325331872785\n",
      "0.00010142865835351552\n",
      "9.493089363765888e-05\n",
      "0.00011319930607709363\n",
      "0.00011219952504753712\n",
      "9.194745807628527e-05\n",
      "0.00012483147043463577\n",
      "0.00012943798193354173\n",
      "0.00019704013795725122\n",
      "0.00013804939695003592\n",
      "0.00010334446784222655\n",
      "0.00010540295725360043\n",
      "0.00012022829857342231\n",
      "0.0001424643358313691\n",
      "0.00022563587990667141\n",
      "0.00029028326427630517\n",
      "0.00021016895803557313\n",
      "0.00010727449628875523\n",
      "0.00011396643707645492\n",
      "0.00014527685392190463\n",
      "9.54755073856879e-05\n",
      "6.798489553165153e-05\n",
      "0.00012073358047101607\n",
      "0.0001425127874076059\n",
      "0.00010701404033698992\n",
      "0.00013583392046333207\n",
      "0.00011908032718429183\n",
      "9.16036069529146e-05\n",
      "8.371086078266635e-05\n",
      "0.0001363399776203635\n",
      "0.0001383699997777124\n",
      "0.00011344901987760258\n",
      "0.0001244383727898135\n",
      "0.00010432252479791901\n",
      "0.00011595155418847814\n",
      "0.00011003573468680271\n",
      "0.00012135954814908069\n",
      "0.00013283099512808227\n",
      "0.0001236773559539723\n",
      "0.00011917156514952568\n",
      "0.00011987257507101275\n",
      "0.0001477721826996658\n",
      "0.0001165265963910943\n",
      "7.867227453499984e-05\n",
      "0.0001203607707367416\n",
      "0.00012333891531654886\n",
      "0.00017089681733415757\n",
      "0.0001337719495150344\n",
      "7.106406289019091e-05\n",
      "7.334699942331715e-05\n",
      "0.00010397076060430504\n",
      "0.00015292188307846664\n",
      "0.00013762367275865002\n",
      "0.00019866629922378002\n",
      "0.00015472642303048306\n",
      "0.00011301910003162667\n",
      "0.00015303262243251985\n",
      "0.00018489249724472706\n",
      "0.0001575580083336423\n",
      "0.00017132931337927732\n",
      "0.00020623185831519897\n",
      "0.00018784686272091237\n",
      "0.00022162378517367166\n",
      "0.00019105743935034862\n",
      "0.00020683246133824102\n",
      "0.00020054418190694235\n",
      "0.0001718055334990422\n",
      "0.0001301697181789895\n",
      "0.00010835184954644299\n",
      "0.00012626761755272874\n",
      "0.00014361032596843902\n",
      "0.0001426663114440097\n",
      "0.00011302231135986916\n",
      "8.672520066223589e-05\n",
      "9.812682241819164e-05\n",
      "0.0001171113780262342\n",
      "0.0001588990083914205\n",
      "0.00011331433352360639\n",
      "0.0002349330210488106\n",
      "0.00030850444678374886\n",
      "0.000345793609756659\n",
      "Epoch: 1; train loss: 0.595324353546036; train accuracy: 0.7918384308510639; test accuracy: 0.7476\n",
      "0.0002676369374024322\n",
      "0.00013823881895969227\n",
      "9.641816766439215e-05\n",
      "0.00018385736889042764\n",
      "0.000256383464761414\n",
      "0.0001622928519527668\n",
      "5.3699497073911067e-05\n",
      "0.00010911395216708751\n",
      "9.20466345449753e-05\n",
      "0.00013428335396892501\n",
      "0.00016550730479993284\n",
      "7.120566017812126e-05\n",
      "0.00012918999746140515\n",
      "0.00015583424238043575\n",
      "0.00026602659510713316\n",
      "0.00020646380056850845\n",
      "0.00010711004411682221\n",
      "0.0001248855429854947\n",
      "0.00013532947545096054\n",
      "8.803906818063424e-05\n",
      "9.02555299670511e-05\n",
      "0.0001287185427992114\n",
      "0.00014887659361419132\n",
      "0.00011112190177377156\n",
      "0.00010759638540654835\n",
      "0.00019736071408571113\n",
      "0.00024120846466643215\n",
      "0.00025903288550610385\n",
      "0.00022090881481384917\n",
      "0.00031616461219633135\n",
      "0.00017824117141891505\n",
      "0.00013973848322759917\n",
      "0.0003631786182806811\n",
      "0.0004240764800981034\n",
      "0.00028387579436541703\n",
      "0.00015583878270453272\n",
      "0.00011686766676468556\n",
      "0.0001682723196866061\n",
      "0.00014360979878464623\n",
      "0.00010083675777842841\n",
      "0.0002069182887526287\n",
      "0.00010697385768608163\n",
      "0.00010664451859621497\n",
      "0.0001356397052539684\n",
      "0.00012201548742117547\n",
      "0.00012599660786344991\n",
      "0.0001558045109445597\n",
      "0.00019284446378617544\n",
      "0.00010102098494554172\n",
      "9.988961817614218e-05\n",
      "7.950406276973746e-05\n",
      "0.00013049968323510365\n",
      "0.00013786630630348214\n",
      "0.00013195204786424058\n",
      "0.00010178960241370674\n",
      "8.704475067911249e-05\n",
      "0.00013993457555787364\n",
      "0.00023681421724081143\n",
      "0.00023822291410055185\n",
      "7.244340267425274e-05\n",
      "0.0001311717471025245\n",
      "0.0001265785036115927\n",
      "9.197683416027696e-05\n",
      "0.0001420246520236055\n",
      "0.00010202279656622321\n",
      "0.00011178484901605727\n",
      "0.00014239286814837613\n",
      "0.00011025100967612286\n",
      "0.00010810582951639041\n",
      "0.00011193169806383002\n",
      "0.0001229989208571659\n",
      "9.32674331149525e-05\n",
      "0.0001682443853072856\n",
      "0.00016105768374850257\n",
      "9.197264444053619e-05\n",
      "9.544498766460988e-05\n",
      "0.00010640021420708551\n",
      "0.00015995259372731673\n",
      "0.00011451970299205822\n",
      "0.00012061949636127597\n",
      "0.00011260255443018429\n",
      "0.00010240457183554405\n",
      "0.00014143190292025535\n",
      "0.0001315125069089503\n",
      "0.00014383310186344883\n",
      "0.00017718799825855268\n",
      "0.00026828796651437025\n",
      "0.00020060412860542457\n",
      "0.00010925159410006508\n",
      "0.00011881676451905038\n",
      "0.00010614981136203229\n",
      "0.0002150016965274082\n",
      "0.00031537697267655055\n",
      "0.00018522279114536842\n",
      "6.987757340959732e-05\n",
      "8.609982313277906e-05\n",
      "0.0001716414628754293\n",
      "0.00020407031441907123\n",
      "8.507608268042258e-05\n",
      "0.00018859698442413313\n",
      "9.007423272847579e-05\n",
      "0.00013382474926625098\n",
      "0.0001476500846901909\n",
      "0.00021749424671691715\n",
      "0.00027462323938149747\n",
      "0.00023322735240913282\n",
      "0.00015506659070512458\n",
      "0.00014200026974422143\n",
      "0.00022317611247242098\n",
      "0.0002813531905193906\n",
      "0.0001832137673843975\n",
      "0.00012752384761737765\n",
      "0.0001166551408070962\n",
      "0.0001211317674809127\n",
      "0.00015825270667951618\n",
      "0.0002637646936685837\n",
      "0.00015454582960371265\n",
      "0.00011161148968555491\n",
      "0.00013847664835878924\n",
      "9.545159697286524e-05\n",
      "0.0001828308825031847\n",
      "0.000254134636778848\n",
      "0.00014804483437009765\n",
      "0.0001033217289503549\n",
      "0.0001245540171553002\n",
      "0.00014645675423171581\n",
      "8.195918995428858e-05\n",
      "0.00016374066505762353\n",
      "0.0002029108973485997\n",
      "0.0001177125321701602\n",
      "0.0001907864718538891\n",
      "0.0002332477327067688\n",
      "0.0001001701488046759\n",
      "0.00017033147013447372\n",
      "0.0001663519009143545\n",
      "0.00019027507446542084\n",
      "0.00018650518381481548\n",
      "0.00014508266662141198\n",
      "0.00011602903902189005\n",
      "0.00012583225358826913\n",
      "9.997795993262577e-05\n",
      "9.272938609196994e-05\n",
      "0.0001902250374141396\n",
      "0.0002854937899013724\n",
      "0.00019839744649235354\n",
      "0.00011581003333520728\n",
      "0.00019150259217886703\n",
      "0.00021401009844505416\n",
      "0.00026577380708240586\n",
      "0.00016350219702821302\n",
      "0.00012500504985762947\n",
      "0.00013280392361563517\n",
      "0.00010737750682925269\n",
      "0.00010514680470570923\n",
      "0.00012111375370255869\n",
      "0.00011214607901825031\n",
      "8.797261383829925e-05\n",
      "0.00010789310492578569\n",
      "0.00011424550696753025\n",
      "0.00010150317635111396\n",
      "0.00013215214861627198\n",
      "0.00014759836295465633\n",
      "0.0002550533183004661\n",
      "0.0002092548212468408\n",
      "0.00015232272153767597\n",
      "0.00011549866965137271\n",
      "0.00014245853432360043\n",
      "0.00014721451599929007\n",
      "0.0002001962164503349\n",
      "0.0002699599910650527\n",
      "0.00024076113419471896\n",
      "0.00014238667461786945\n",
      "0.00017942827610705695\n",
      "0.00016033960477456843\n",
      "0.00011683614711898205\n",
      "8.723743887364046e-05\n",
      "0.00011245307906249684\n",
      "0.00015492267661031396\n",
      "0.00014255778040118345\n",
      "0.00016295463954017663\n",
      "0.00012328016900139873\n",
      "0.00011386604777564256\n",
      "7.973511275386573e-05\n",
      "0.00013701867503195143\n",
      "0.00015456113958931103\n",
      "0.00015081729463822512\n",
      "0.00016645988979968485\n",
      "0.00013724020546751576\n",
      "0.00013780368142121582\n",
      "0.000117621236558687\n",
      "0.000129493685127685\n",
      "0.00016838696900682424\n",
      "0.00013483593043579263\n",
      "0.00012589964694906613\n",
      "0.000137693400068465\n",
      "0.0001802202784412223\n",
      "0.00014134179020096745\n",
      "6.929343717627625e-05\n",
      "0.0001373517599391469\n",
      "0.0001624412188576694\n",
      "0.00019764502668627253\n",
      "0.0001566165813676859\n",
      "0.00010402682981145235\n",
      "9.274214434134758e-05\n",
      "0.00010868751233789257\n",
      "0.00017317173360389395\n",
      "0.00014858538901271631\n",
      "0.00026208342306533806\n",
      "0.00022749921186225998\n",
      "0.00013133445646120844\n",
      "0.00017456279734526893\n",
      "0.00020843257593740905\n",
      "0.00019489907263512638\n",
      "0.00022974446462823846\n",
      "0.00025977674712961255\n",
      "0.0001971889745995975\n",
      "0.00022679048074618802\n",
      "0.00018726682731015187\n",
      "0.00020564581088658193\n",
      "0.0001851504498284074\n",
      "0.00017735375774947715\n",
      "0.00014907164528335553\n",
      "0.00013268987002950904\n",
      "0.00015540362797573484\n",
      "0.0001574355899264815\n",
      "0.00014573502887665484\n",
      "0.00012096530192815731\n",
      "0.00010057243124967757\n",
      "0.00010724598298742564\n",
      "0.0001493336378051159\n",
      "0.0001616715516547328\n",
      "0.00012838271965977664\n",
      "0.0002475291126448737\n",
      "0.00030773193947559877\n",
      "0.00033355298286722314\n",
      "Epoch: 2; train loss: 0.5186768856309704; train accuracy: 0.8211159131205673; test accuracy: 0.7809\n",
      "0.00023837676504105578\n",
      "0.00011639298674955115\n",
      "9.693078649005399e-05\n",
      "0.000222534338189688\n",
      "0.00033048242846848617\n",
      "0.00024278763215190296\n",
      "8.802172896671546e-05\n",
      "0.00011495069803237982\n",
      "9.699240791737443e-05\n",
      "0.00015656327522009628\n",
      "0.0002113785343328654\n",
      "7.22422772869958e-05\n",
      "0.00011914757944796794\n",
      "0.00016534954704759764\n",
      "0.00026706487745350446\n",
      "0.00020980295366121562\n",
      "0.00010465753886298784\n",
      "0.00012513028331730662\n",
      "0.0001318629076338962\n",
      "8.328327704225079e-05\n",
      "0.0001033866079462599\n",
      "0.00015222234545534598\n",
      "0.00016572052037448922\n",
      "9.844931209490704e-05\n",
      "0.00012990467010728338\n",
      "0.00020861599409307277\n",
      "0.00023562862024998425\n",
      "0.00027270882912169554\n",
      "0.00023194742366515307\n",
      "0.0003437826370963379\n",
      "0.00022806829137918608\n",
      "0.0001867549041216184\n",
      "0.000401439919541173\n",
      "0.0004667269814515757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00032289583090385865\n",
      "0.00019581940650627202\n",
      "0.00013308980003105386\n",
      "0.00018222140502106114\n",
      "0.00015219630669411726\n",
      "0.00012944224274224586\n",
      "0.0002939307961986482\n",
      "0.00017190159892312997\n",
      "0.00012007427302630864\n",
      "0.00016155575176482722\n",
      "0.00014974995888157266\n",
      "0.00017968839000800916\n",
      "0.00021180904176507046\n",
      "0.0002289242068739144\n",
      "0.00011713422440627166\n",
      "0.00011581270535898412\n",
      "7.599014400981312e-05\n",
      "0.00013846937009789147\n",
      "0.00015866786945820742\n",
      "0.00015765982911750625\n",
      "0.00011551360858959994\n",
      "9.457938279885875e-05\n",
      "0.00014148205455224422\n",
      "0.00023811099408585206\n",
      "0.00023227239823556229\n",
      "9.015547442899245e-05\n",
      "0.00014967062230666916\n",
      "0.00013937998416661858\n",
      "9.777890225436084e-05\n",
      "0.0001587140169475211\n",
      "0.0001216721892429399\n",
      "0.00013435597669185132\n",
      "0.00016165863114557492\n",
      "0.00012391724322025988\n",
      "0.00010663575947560892\n",
      "0.00013914510463587386\n",
      "0.00016677725309943234\n",
      "0.0001311532951636703\n",
      "0.00018289630236124327\n",
      "0.00015443437595991655\n",
      "0.00010348013307712345\n",
      "0.00011892201307882293\n",
      "0.00010522248340857793\n",
      "0.00016175981398363495\n",
      "0.00011263417294624231\n",
      "0.00013733556349981927\n",
      "0.0001277153024418874\n",
      "0.00010104255184541803\n",
      "0.00013741530767123544\n",
      "0.0001374791796026471\n",
      "0.00015024358365992434\n",
      "0.00018781298990933892\n",
      "0.00029171037395522885\n",
      "0.00021981659797883757\n",
      "0.00011545353228637446\n",
      "0.00012070537662716636\n",
      "0.00012766792209788455\n",
      "0.00019875310860336886\n",
      "0.00028532400931966943\n",
      "0.00017301531946453178\n",
      "7.478521490730202e-05\n",
      "9.291349960194567e-05\n",
      "0.00018624292833494988\n",
      "0.00022999038116683959\n",
      "9.94143224149238e-05\n",
      "0.00022289492959929276\n",
      "0.00015309850479411913\n",
      "0.0001760949221594977\n",
      "0.000165072190743282\n",
      "0.00021856364832279328\n",
      "0.00027105455697078634\n",
      "0.00022949994748832674\n",
      "0.00016057541111358953\n",
      "0.00015351045820642637\n",
      "0.00024186404938239138\n",
      "0.00034070307067837465\n",
      "0.00024583512202818424\n",
      "0.00014171528776194572\n",
      "0.00011399089949640893\n",
      "0.0001300904980267439\n",
      "0.00016212761858900166\n",
      "0.0002744758735530427\n",
      "0.00019423725990368266\n",
      "0.00011714428144806075\n",
      "0.00013710212586160706\n",
      "9.643527290704444e-05\n",
      "0.00019720692560920182\n",
      "0.00030504758536688254\n",
      "0.00019090168364580446\n",
      "0.00016589864096948866\n",
      "0.0001642898512217047\n",
      "0.00014937511233231198\n",
      "9.643690181937385e-05\n",
      "0.00017960237210562887\n",
      "0.00022394128133847556\n",
      "0.00014118075385515858\n",
      "0.0001854166445309953\n",
      "0.0002608406557638459\n",
      "0.00015387773662642478\n",
      "0.00015591757226087296\n",
      "0.0001518748314516921\n",
      "0.00022612469798678148\n",
      "0.0002071407666470206\n",
      "0.00013535292749269654\n",
      "0.0001343906894865302\n",
      "0.0001503106461190604\n",
      "0.00010713971012122161\n",
      "0.00010529616796194716\n",
      "0.00020516286939508777\n",
      "0.000330898632481711\n",
      "0.00023957437351259354\n",
      "0.00010986875838329957\n",
      "0.00022943824283048103\n",
      "0.00027527890560188184\n",
      "0.00036977779514363475\n",
      "0.00022410185203833308\n",
      "0.0001359021910713293\n",
      "0.00015368306856839488\n",
      "0.00010155512208584645\n",
      "0.00010934991422533999\n",
      "0.00012903081448379454\n",
      "0.00012675918356897295\n",
      "8.919356236196358e-05\n",
      "0.00010299857405243876\n",
      "0.00011596400970616223\n",
      "0.00011285059291690266\n",
      "0.00013989422680928126\n",
      "0.0001580735631187922\n",
      "0.0002840842039015622\n",
      "0.00025291292599396986\n",
      "0.0002052528061430476\n",
      "0.00013518829070227725\n",
      "0.00015583142714960648\n",
      "0.00015469161932725345\n",
      "0.0001822313378497435\n",
      "0.0002463755217766274\n",
      "0.00027160571209740195\n",
      "0.00019531814623450765\n",
      "0.00020963245266061278\n",
      "0.0001672324972365571\n",
      "0.00010576709575101276\n",
      "9.333603798722264e-05\n",
      "0.00011335237937344066\n",
      "0.0001500832938226135\n",
      "0.00015901554072437864\n",
      "0.00017180680333050044\n",
      "0.0001169727226046455\n",
      "0.00012598707693535602\n",
      "7.891382634072798e-05\n",
      "0.0001413098303107524\n",
      "0.00017302373983769877\n",
      "0.00018041090297736488\n",
      "0.0001825484358385525\n",
      "0.00014123236800414702\n",
      "0.00014884989494900222\n",
      "0.0001211615488436775\n",
      "0.00012695259231257423\n",
      "0.00017537958307457615\n",
      "0.00012611309292942884\n",
      "0.00012753907762962763\n",
      "0.00014807948090422922\n",
      "0.000198402866546893\n",
      "0.00016068839465993372\n",
      "7.743935399003524e-05\n",
      "0.00014144395879977102\n",
      "0.00020071517297400108\n",
      "0.0002315510962944093\n",
      "0.00015954253504950902\n",
      "0.00012201012581777686\n",
      "0.00010503728508438045\n",
      "0.0001160824125563157\n",
      "0.0001874740528967175\n",
      "0.00013725418196016442\n",
      "0.00026707086727610245\n",
      "0.00025532227121558807\n",
      "0.0001408788320826099\n",
      "0.0001778730828770404\n",
      "0.00021391391704255852\n",
      "0.0002085118376093236\n",
      "0.0002527837037725354\n",
      "0.00030172066634602453\n",
      "0.00020330122326808232\n",
      "0.00022523126986866021\n",
      "0.00017099080154843495\n",
      "0.00019253243991652335\n",
      "0.00016681726452449797\n",
      "0.0001697263474579891\n",
      "0.00015009110126617002\n",
      "0.00014258330791096162\n",
      "0.0001685069618315769\n",
      "0.00015599098968493085\n",
      "0.00014041928642676303\n",
      "0.00011598580912119156\n",
      "0.00011335998890873574\n",
      "0.00011336545677672363\n",
      "0.00016107924404039532\n",
      "0.00016849518408122537\n",
      "0.00013402720677683691\n",
      "0.00025792271990373206\n",
      "0.0002984432848449815\n",
      "0.000310442669557047\n",
      "Epoch: 3; train loss: 0.4843656341621772; train accuracy: 0.8307070035460992; test accuracy: 0.8067\n",
      "0.00021065369169964002\n",
      "0.00010721538865303949\n",
      "0.00010327040216820898\n",
      "0.00024839362742276675\n",
      "0.000381808677258946\n",
      "0.0003028563793506386\n",
      "0.00013505541634920536\n",
      "0.00014034347195641603\n",
      "0.00010640637738671436\n",
      "0.00015284892786913867\n",
      "0.000230193064014208\n",
      "0.00010835227078807477\n",
      "0.00011635391798120344\n",
      "0.0001661834392072805\n",
      "0.00025988397648054804\n",
      "0.00020552916491169455\n",
      "0.00010194533899365662\n",
      "0.00011950512643198901\n",
      "0.00012790263723871917\n",
      "8.316759992199758e-05\n",
      "0.00011930075326670534\n",
      "0.00017652930377955284\n",
      "0.00018348928682909924\n",
      "9.655584094945998e-05\n",
      "0.00013667363773335356\n",
      "0.00021302941813142198\n",
      "0.00022859370709696925\n",
      "0.0002743261603807749\n",
      "0.00022961741736686757\n",
      "0.00034861169964659297\n",
      "0.0002541542851460723\n",
      "0.00022915779422809276\n",
      "0.0004188548202471508\n",
      "0.00047912844490948853\n",
      "0.00035143381923299585\n",
      "0.00023468430794771125\n",
      "0.0001627942485900032\n",
      "0.00019713943736126592\n",
      "0.00016314707054264157\n",
      "0.00014254153962709975\n",
      "0.0003547934771391278\n",
      "0.00022019902815030012\n",
      "0.0001271483251955381\n",
      "0.00018129857892605644\n",
      "0.00018108328037297575\n",
      "0.00023527687729692646\n",
      "0.0002692751889965189\n",
      "0.0002862813200589382\n",
      "0.00017267909426822887\n",
      "0.00014848160379526615\n",
      "8.083274732064572e-05\n",
      "0.00014173167561663482\n",
      "0.00017178556481665073\n",
      "0.00017526726842786918\n",
      "0.00012598212952432135\n",
      "9.830895068643494e-05\n",
      "0.00014049002710973794\n",
      "0.00024100165441084365\n",
      "0.00022998190648123427\n",
      "0.00011197138974491671\n",
      "0.000168131456705974\n",
      "0.00015149557433504155\n",
      "0.00011231801002262481\n",
      "0.00017771274144734204\n",
      "0.00014135336505357863\n",
      "0.00015614443549560677\n",
      "0.0001837163196085467\n",
      "0.0001345377242021944\n",
      "9.724977336765213e-05\n",
      "0.0001436705608264362\n",
      "0.00018997780294989253\n",
      "0.0001618358517544505\n",
      "0.00019669786690287402\n",
      "0.0001552781186719768\n",
      "0.0001249357294174619\n",
      "0.00014073760466862896\n",
      "0.00010880217158506614\n",
      "0.00016538610538457195\n",
      "0.0001113059624763086\n",
      "0.00014496873385641562\n",
      "0.00013919153954749516\n",
      "9.807525165689324e-05\n",
      "0.00013016019690106692\n",
      "0.00013837416293786716\n",
      "0.0001594251609540856\n",
      "0.00019014398405433404\n",
      "0.0002975533289034621\n",
      "0.000223687933446447\n",
      "0.0001249739870717436\n",
      "0.00012416480615428405\n",
      "0.00014512084201190407\n",
      "0.00019768479588466557\n",
      "0.0002764662273637681\n",
      "0.00017170724890200337\n",
      "8.700457068918834e-05\n",
      "0.00010411524646476906\n",
      "0.0001918420172017029\n",
      "0.0002259910051097687\n",
      "0.00010173480517980765\n",
      "0.00024156682597986106\n",
      "0.00020186569650117446\n",
      "0.00021089470615813028\n",
      "0.00018076019106187197\n",
      "0.00021885859153592712\n",
      "0.0002663183829613243\n",
      "0.00022681078692623954\n",
      "0.00017088944501452238\n",
      "0.00016029804320892514\n",
      "0.0002555467818401914\n",
      "0.00037580738748707154\n",
      "0.00028774456099896775\n",
      "0.0001616816348978682\n",
      "0.00012284453619977855\n",
      "0.00013397546267368375\n",
      "0.00016633744598712588\n",
      "0.0002734090735318289\n",
      "0.0002078893189118093\n",
      "0.00012568472173523593\n",
      "0.0001372168075207095\n",
      "9.41155987102284e-05\n",
      "0.00020254019812883443\n",
      "0.0003335224703442363\n",
      "0.0002197729205373007\n",
      "0.0002097528057756917\n",
      "0.00019744898032000423\n",
      "0.00015642462576902796\n",
      "0.00011134770376705428\n",
      "0.00018879420834743836\n",
      "0.00023562190013288125\n",
      "0.00015361302132356288\n",
      "0.00018326177159187312\n",
      "0.0002756751494726672\n",
      "0.00019146611641942\n",
      "0.00016877865131243515\n",
      "0.0001462739782411564\n",
      "0.00024112135141588\n",
      "0.0002231904949001358\n",
      "0.00013392674650455002\n",
      "0.00014112561628455057\n",
      "0.00016057357061769403\n",
      "0.00011051529215921027\n",
      "0.00011411006465167272\n",
      "0.00020759424058967526\n",
      "0.00033539564025722587\n",
      "0.0002496656564949171\n",
      "0.00010561271636108734\n",
      "0.0002427465508638975\n",
      "0.0003062833308170254\n",
      "0.0004350510168196833\n",
      "0.00026260030922335367\n",
      "0.00014566971596254158\n",
      "0.0001710065199751707\n",
      "9.665220717675888e-05\n",
      "0.00010668578080599946\n",
      "0.00013553334669318522\n",
      "0.00013790009730817057\n",
      "9.387610629599845e-05\n",
      "0.00010159417758819228\n",
      "0.00012017670134913686\n",
      "0.00012352342502098987\n",
      "0.00014681932693057006\n",
      "0.00016732657155461728\n",
      "0.0003023437630916032\n",
      "0.00027712035661368867\n",
      "0.00024010605352825344\n",
      "0.0001531685790405831\n",
      "0.00016267801095697098\n",
      "0.00016124474128870807\n",
      "0.00017399650508025813\n",
      "0.00022523971261842165\n",
      "0.00028062059695016685\n",
      "0.00022490982627813359\n",
      "0.00022541737470268443\n",
      "0.00017389478152990396\n",
      "9.331717629946285e-05\n",
      "9.294524904789403e-05\n",
      "0.00011948279431659667\n",
      "0.00015149449363984489\n",
      "0.00017481782709877355\n",
      "0.00018165100058699582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00011626054774343493\n",
      "0.0001316040775507084\n",
      "7.95992112593444e-05\n",
      "0.0001476759668404369\n",
      "0.0001933880722921564\n",
      "0.0002055365437523025\n",
      "0.00019237157935407995\n",
      "0.0001440377810249381\n",
      "0.00015797590647169673\n",
      "0.00012393684812944664\n",
      "0.00012456421170351666\n",
      "0.00017143859967379846\n",
      "0.00011663933580087607\n",
      "0.0001325373056319502\n",
      "0.00015502648002803165\n",
      "0.0002081766452706116\n",
      "0.0001728729623807908\n",
      "9.03708729174059e-05\n",
      "0.00014325065182688065\n",
      "0.00022126722167342108\n",
      "0.00025119363088298423\n",
      "0.00015760804216192423\n",
      "0.00012830390207486987\n",
      "0.00010911905598604471\n",
      "0.00012422923708640246\n",
      "0.0001966826360601749\n",
      "0.00013165621115106697\n",
      "0.0002689543556341777\n",
      "0.00026932348328048895\n",
      "0.000147108188219195\n",
      "0.0001861417856612665\n",
      "0.00022303429294483272\n",
      "0.000221042019211891\n",
      "0.00026702115130058235\n",
      "0.00033503825595569383\n",
      "0.00021370383114619322\n",
      "0.00022629627193007797\n",
      "0.0001635408369766058\n",
      "0.00018937275934182405\n",
      "0.00016119296059368554\n",
      "0.00016497378044792298\n",
      "0.00014624025066011984\n",
      "0.00014361196382713912\n",
      "0.0001757578303974938\n",
      "0.00015833436895710276\n",
      "0.0001381082713119868\n",
      "0.00011154842346695911\n",
      "0.00012362275859939312\n",
      "0.00012003424244534833\n",
      "0.0001636862671015188\n",
      "0.0001765538491069689\n",
      "0.00013956601723568904\n",
      "0.00026496474625845544\n",
      "0.00029040584882422085\n",
      "0.00029337017957146435\n",
      "Epoch: 4; train loss: 0.46472664859310236; train accuracy: 0.8384363918439716; test accuracy: 0.817\n",
      "0.00019431923692851997\n",
      "0.00010697604199134925\n",
      "0.00010686432238260393\n",
      "0.00026312768517141965\n",
      "0.0004084442129157796\n",
      "0.00033229475791142737\n",
      "0.0001644225040182809\n",
      "0.00016750784430442277\n",
      "0.0001310219412389463\n",
      "0.00014888468409853575\n",
      "0.0002362769713910409\n",
      "0.00012829150474033996\n",
      "0.00012540845652730864\n",
      "0.0001712991041632761\n",
      "0.0002561648937399177\n",
      "0.00020508564520210632\n",
      "0.00010409307766125135\n",
      "0.00012183700397811458\n",
      "0.00013100132023849664\n",
      "8.575509675984687e-05\n",
      "0.00013263941137100707\n",
      "0.00019586601515106503\n",
      "0.00019523152062370357\n",
      "9.710754061537338e-05\n",
      "0.00014434373905339616\n",
      "0.00021730453360273668\n",
      "0.00022571076411980896\n",
      "0.00027470253345567475\n",
      "0.00022895058721316604\n",
      "0.00035429449033253977\n",
      "0.00027014557648939817\n",
      "0.000256362836522998\n",
      "0.0004302052070199281\n",
      "0.0004888172852138068\n",
      "0.00037534046621810546\n",
      "0.00025918710145770776\n",
      "0.00017843851326946797\n",
      "0.00020437437137552165\n",
      "0.00017033751778886856\n",
      "0.00015502933841811186\n",
      "0.00039497991012960547\n",
      "0.00024679073324040805\n",
      "0.00013635542538391907\n",
      "0.0001977208393216122\n",
      "0.00020553055605870114\n",
      "0.0002763268635317456\n",
      "0.0003092977569187673\n",
      "0.00032406007393115204\n",
      "0.00020634030614381118\n",
      "0.0001698994094377571\n",
      "9.496463572879303e-05\n",
      "0.00014664495133994627\n",
      "0.00018218705726450008\n",
      "0.00018475513428760528\n",
      "0.00012911625900371607\n",
      "0.00010330441951832535\n",
      "0.00014403407299042428\n",
      "0.0002450642079634663\n",
      "0.0002321678128433917\n",
      "0.0001259228938916341\n",
      "0.0001800914453586514\n",
      "0.0001623538134992559\n",
      "0.00012237063641087136\n",
      "0.0001903967309299676\n",
      "0.0001536656972563395\n",
      "0.00017165596525663506\n",
      "0.0002018236799214815\n",
      "0.00014327583730842393\n",
      "9.217821245998271e-05\n",
      "0.00014496437457800214\n",
      "0.00020119267205457957\n",
      "0.0001766672348192821\n",
      "0.00020329813283354893\n",
      "0.0001583289807825436\n",
      "0.00013434672367444245\n",
      "0.00014852630145018307\n",
      "0.00010828492738547933\n",
      "0.00017122698793983407\n",
      "0.00011387853590252468\n",
      "0.0001526271409764204\n",
      "0.00014839458373620444\n",
      "9.970103578553285e-05\n",
      "0.00012734657712145227\n",
      "0.00014080876669404673\n",
      "0.0001677006094237372\n",
      "0.00019185228946206912\n",
      "0.00029986612772847193\n",
      "0.0002252343836402239\n",
      "0.0001328581555656904\n",
      "0.00012935258075109956\n",
      "0.00016115321930103047\n",
      "0.0001991116543339734\n",
      "0.0002736661310318784\n",
      "0.000172845648694653\n",
      "9.647214011959215e-05\n",
      "0.00011426559998375862\n",
      "0.00019689552490683376\n",
      "0.00021907571106049157\n",
      "0.00010031153733311174\n",
      "0.00025254532403168263\n",
      "0.00022601258089749923\n",
      "0.00022705031674296607\n",
      "0.00018747862906198852\n",
      "0.00022064389868433473\n",
      "0.00026319640729654756\n",
      "0.00022779368185689037\n",
      "0.00018121660007406858\n",
      "0.00016185229005498725\n",
      "0.00026738553418919237\n",
      "0.00039554710840983346\n",
      "0.0003048140678105545\n",
      "0.000165463174580395\n",
      "0.00012248083060926914\n",
      "0.00014498186440406382\n",
      "0.00017038122899063306\n",
      "0.0002729548897704392\n",
      "0.00020869665085794016\n",
      "0.00012866566847798076\n",
      "0.00014040675796803172\n",
      "9.200658503133224e-05\n",
      "0.00020402702724025515\n",
      "0.00034496003621417305\n",
      "0.00023107109428651613\n",
      "0.00023025966709263148\n",
      "0.00021430421598121974\n",
      "0.00016735646248841856\n",
      "0.00012563861980523369\n",
      "0.0001934242234666081\n",
      "0.00024077570099171174\n",
      "0.0001552453137746397\n",
      "0.00019096390482069625\n",
      "0.0002900349398768515\n",
      "0.00021080411732006678\n",
      "0.00018127192896559994\n",
      "0.00014705238596286055\n",
      "0.0002506991971757216\n",
      "0.00023568988076864394\n",
      "0.00013629486583871303\n",
      "0.00014334252551795684\n",
      "0.00016367337227402818\n",
      "0.00011280080368618835\n",
      "0.0001234161256120511\n",
      "0.0002085936561203532\n",
      "0.00032709939106628316\n",
      "0.00024409015629316716\n",
      "0.00010740720564610854\n",
      "0.00024979405629022526\n",
      "0.0003232324380778605\n",
      "0.0004727740826096093\n",
      "0.00028430319508108374\n",
      "0.00015517204776558218\n",
      "0.00018497302876763536\n",
      "9.524657987881722e-05\n",
      "0.0001033703289068914\n",
      "0.00014005557654423153\n",
      "0.0001462385629138579\n",
      "9.801498875401099e-05\n",
      "0.00010194685546347019\n",
      "0.00012549474408894874\n",
      "0.00013094077647947015\n",
      "0.00015280097863125869\n",
      "0.00017495037693745645\n",
      "0.00031409514322204503\n",
      "0.00028971406825152406\n",
      "0.00025593723078147317\n",
      "0.0001617242790845182\n",
      "0.0001672570936845571\n",
      "0.00016506503119579298\n",
      "0.00017109448102909717\n",
      "0.00021377836501837064\n",
      "0.0002833629305704377\n",
      "0.00024103683634887717\n",
      "0.00023629375298409724\n",
      "0.0001796880617069476\n",
      "8.763312724058013e-05\n",
      "9.342151684194518e-05\n",
      "0.0001263021201407262\n",
      "0.00015567368710049008\n",
      "0.00018823067072258514\n",
      "0.00019018290498585183\n",
      "0.00011930358630886064\n",
      "0.0001351811151532417\n",
      "8.026592540202423e-05\n",
      "0.00015273129772587152\n",
      "0.00020619623775809318\n",
      "0.00022064023756813335\n",
      "0.00019673455765862764\n",
      "0.00014605635097948008\n",
      "0.00016634475407549323\n",
      "0.00012615369555883958\n",
      "0.00012393406221556904\n",
      "0.00016596937941607755\n",
      "0.0001088739314228591\n",
      "0.00013957184703869841\n",
      "0.00016008783985142563\n",
      "0.00021314663592560774\n",
      "0.0001782274162114492\n",
      "9.838203640123158e-05\n",
      "0.00014579795560301783\n",
      "0.0002352013855897979\n",
      "0.0002604130777061748\n",
      "0.00015588640316910958\n",
      "0.0001351865657251257\n",
      "0.00011210719645444367\n",
      "0.00013182034594211943\n",
      "0.00020254696156042951\n",
      "0.00013246258034211705\n",
      "0.0002791258647006073\n",
      "0.0002811156295888564\n",
      "0.00015154480859699837\n",
      "0.00019898376476687628\n",
      "0.00023544353950904768\n",
      "0.00023456589888677548\n",
      "0.00027879569425275\n",
      "0.0003544994315882709\n",
      "0.0002180156232185854\n",
      "0.00022814264547683905\n",
      "0.0001612373110209864\n",
      "0.0001908731853135889\n",
      "0.0001614318806334422\n",
      "0.00016363253374226293\n",
      "0.00014267376495587708\n",
      "0.000139709300101791\n",
      "0.00017766927834907733\n",
      "0.000162341592738336\n",
      "0.00013909516397851628\n",
      "0.00010875349532395822\n",
      "0.0001301178758093302\n",
      "0.00012608811298463998\n",
      "0.00016690807112068815\n",
      "0.00018336423716595396\n",
      "0.00014528775080900635\n",
      "0.0002690825501710333\n",
      "0.00028542011854041976\n",
      "0.0002823360301129088\n",
      "Epoch: 5; train loss: 0.4515883954346477; train accuracy: 0.8433732269503545; test accuracy: 0.8245\n",
      "0.00018500647351480913\n",
      "0.00010998906921267439\n",
      "0.00010803449588703746\n",
      "0.0002712766614297338\n",
      "0.00041820045814607167\n",
      "0.00034344796132443453\n",
      "0.00017855848794875187\n",
      "0.00018288283730980687\n",
      "0.00015089561122231922\n",
      "0.0001512222755581602\n",
      "0.00024087879381090653\n",
      "0.00013566941025075697\n",
      "0.00013313356251789578\n",
      "0.00017861401822969426\n",
      "0.00025617763892595767\n",
      "0.00020745346109720335\n",
      "0.0001067498446019687\n",
      "0.0001277898783428984\n",
      "0.00013749055458791353\n",
      "9.051672784899906e-05\n",
      "0.00014524473271841187\n",
      "0.00021104846509648257\n",
      "0.0002016465289152413\n",
      "9.578220268476306e-05\n",
      "0.00015432429282005147\n",
      "0.00022099322311993372\n",
      "0.0002244291534100636\n",
      "0.0002746539916239522\n",
      "0.00022986570440384073\n",
      "0.00036002164368637783\n",
      "0.00027815002995447235\n",
      "0.00026880815272293547\n",
      "0.0004370979997898367\n",
      "0.0004978898172909174\n",
      "0.0003925262784212167\n",
      "0.00027235934932719923\n",
      "0.00018070694293137037\n",
      "0.00020537174969593682\n",
      "0.00017642387353385518\n",
      "0.00016913169645992707\n",
      "0.0004225652380647947\n",
      "0.00026042025118055057\n",
      "0.0001467281936508765\n",
      "0.0002117991677457836\n",
      "0.00022395158246418968\n",
      "0.0003032261788574345\n",
      "0.0003313257555218858\n",
      "0.0003386601338436448\n",
      "0.00021553685494520795\n",
      "0.00017458319477953199\n",
      "9.682244986741435e-05\n",
      "0.00014976057753320827\n",
      "0.00018778776211242788\n",
      "0.0001866104570270118\n",
      "0.00012734066320017258\n",
      "0.00010833277525110667\n",
      "0.00014964580939228722\n",
      "0.00024878897219296925\n",
      "0.00023395528097985778\n",
      "0.0001360045760783279\n",
      "0.00018821095348743515\n",
      "0.0001701871253068125\n",
      "0.00012800883583271352\n",
      "0.0001981799447807625\n",
      "0.00015947795711748538\n",
      "0.00018074300931787693\n",
      "0.00021295121946098748\n",
      "0.0001491534234998048\n",
      "9.073700502520707e-05\n",
      "0.000146234928347928\n",
      "0.00020807366784487207\n",
      "0.00018383886768344034\n",
      "0.0002053369380810289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00016033543777242248\n",
      "0.00013564561703823528\n",
      "0.00014826255601123266\n",
      "0.00010474993615512309\n",
      "0.00017884640158677742\n",
      "0.00011912718081509032\n",
      "0.00015812163219498142\n",
      "0.00015611230976116913\n",
      "0.00010274681645581913\n",
      "0.0001268853932321221\n",
      "0.0001433796391128234\n",
      "0.00017465441362564385\n",
      "0.00019457727490068344\n",
      "0.00030121208905723395\n",
      "0.00022606563487840125\n",
      "0.00013981116823387626\n",
      "0.00013440234218029852\n",
      "0.0001726319471498829\n",
      "0.00019835100158296514\n",
      "0.00027161967057408185\n",
      "0.00017300716054245187\n",
      "0.00010174340929256468\n",
      "0.00012186731571098038\n",
      "0.0002025371291507151\n",
      "0.00021391837927162263\n",
      "9.884136080320181e-05\n",
      "0.00026053795789703164\n",
      "0.00023842573577259715\n",
      "0.00023237522980537026\n",
      "0.00018779213144029535\n",
      "0.0002240719544389373\n",
      "0.00026091819663324485\n",
      "0.00022918123879778782\n",
      "0.0001893870964371673\n",
      "0.00016153884393916687\n",
      "0.00027827959935427913\n",
      "0.0004083916266209378\n",
      "0.00031019904273027753\n",
      "0.00015980604510475386\n",
      "0.00011712630633146494\n",
      "0.00015989444974219354\n",
      "0.0001733130595926192\n",
      "0.00027410029904924787\n",
      "0.00020839951467695888\n",
      "0.00013028139204333884\n",
      "0.00014613870673833862\n",
      "9.079169818384816e-05\n",
      "0.00020569562515841173\n",
      "0.00035203486523968034\n",
      "0.00023481593073244913\n",
      "0.0002397963449646778\n",
      "0.00022148105085995773\n",
      "0.00017829315244827462\n",
      "0.00013932003560939064\n",
      "0.00019672766156822205\n",
      "0.00024206484183345644\n",
      "0.00015200684381108602\n",
      "0.00020297026730617637\n",
      "0.00030276208105850516\n",
      "0.00022058090455436946\n",
      "0.00018849940038917354\n",
      "0.00015062102325982674\n",
      "0.00025819077082841585\n",
      "0.000245815309788236\n",
      "0.00013835415119712062\n",
      "0.0001428334082500474\n",
      "0.00016316292435909112\n",
      "0.00011566654068823892\n",
      "0.00013308894766214413\n",
      "0.0002101447136256175\n",
      "0.0003171298536877564\n",
      "0.00023453556490764414\n",
      "0.00011389736685397996\n",
      "0.00025550447175732026\n",
      "0.0003343050575577141\n",
      "0.0004957809475831374\n",
      "0.0002964615605336445\n",
      "0.0001628313268696512\n",
      "0.0001945808678505467\n",
      "9.65423994371332e-05\n",
      "0.00010100546992691497\n",
      "0.0001438736475060625\n",
      "0.00015319546812502202\n",
      "0.00010157674943872266\n",
      "0.00010332512007478688\n",
      "0.00013032859867748668\n",
      "0.0001364119322287498\n",
      "0.00015831427632053088\n",
      "0.00018143818833574505\n",
      "0.00032203330233912346\n",
      "0.0002965388618888571\n",
      "0.0002618030925722191\n",
      "0.00016470256655784908\n",
      "0.00017070781526967003\n",
      "0.00016615809027608843\n",
      "0.00016997057200520403\n",
      "0.00021194196259022554\n",
      "0.00028969901908562157\n",
      "0.00025248348726135747\n",
      "0.00024455250608846214\n",
      "0.0001845185220545405\n",
      "8.497784063621854e-05\n",
      "9.416128264475376e-05\n",
      "0.0001320365072603327\n",
      "0.00016015367579046087\n",
      "0.00019801248235703145\n",
      "0.00019732848661020136\n",
      "0.00012394833362700124\n",
      "0.00013722810674140926\n",
      "8.122786637489072e-05\n",
      "0.0001574429134591112\n",
      "0.00021380050987631973\n",
      "0.00022899473786938687\n",
      "0.00019772865908407238\n",
      "0.00014661411393296925\n",
      "0.0001741989777965719\n",
      "0.00012826917165693324\n",
      "0.0001243879600232775\n",
      "0.00016146110264087364\n",
      "0.00010445397633838934\n",
      "0.00014797584787108205\n",
      "0.0001645831481710304\n",
      "0.0002162546915282028\n",
      "0.00018154841600029705\n",
      "0.00010301872318725942\n",
      "0.0001484632597661893\n",
      "0.0002458806488906966\n",
      "0.000266647488346174\n",
      "0.0001563610636301052\n",
      "0.00014243395862304108\n",
      "0.00011470818467945034\n",
      "0.0001386073797437099\n",
      "0.0002083248591287737\n",
      "0.00013394605949859008\n",
      "0.0002855239525793932\n",
      "0.00028668536620405385\n",
      "0.0001552258103231831\n",
      "0.00021115596056108107\n",
      "0.000246002372132331\n",
      "0.0002438918264375862\n",
      "0.00028455449850716633\n",
      "0.00036352557145948196\n",
      "0.00021801205810422896\n",
      "0.00022999993311501195\n",
      "0.00016071183110906892\n",
      "0.00019338860846612158\n",
      "0.00016218669339827208\n",
      "0.00016243395500414466\n",
      "0.00013865406178951805\n",
      "0.0001330293503073819\n",
      "0.00017709511978648308\n",
      "0.0001677631251609961\n",
      "0.0001436664888630539\n",
      "0.00010721714805454071\n",
      "0.00013330264008282042\n",
      "0.0001318221621786412\n",
      "0.00017138772953494345\n",
      "0.00018842634386299648\n",
      "0.00015037459406407394\n",
      "0.0002734053173024468\n",
      "0.00028411337008815224\n",
      "0.0002764075667314461\n",
      "Epoch: 6; train loss: 0.44185334505476076; train accuracy: 0.8463264627659575; test accuracy: 0.8299\n",
      "0.00018076248652915488\n",
      "0.0001139774038537416\n",
      "0.00010919334750321152\n",
      "0.00027795520122453457\n",
      "0.0004212047840686963\n",
      "0.0003448673575829193\n",
      "0.00018258336609220809\n",
      "0.00018966108225849373\n",
      "0.00016327136069507872\n",
      "0.00015448086058209032\n",
      "0.0002449746823560626\n",
      "0.00013999953245338756\n",
      "0.000138815062766615\n",
      "0.00018450004490881604\n",
      "0.0002572535558353182\n",
      "0.00021067659239075792\n",
      "0.00010931119678545447\n",
      "0.00013471838311269509\n",
      "0.0001447324734447367\n",
      "9.411243488023172e-05\n",
      "0.0001541731310917162\n",
      "0.00022138923297327512\n",
      "0.00020485594741591413\n",
      "9.4637771991903e-05\n",
      "0.00016416232580847924\n",
      "0.00022352230727971006\n",
      "0.00022384724897444265\n",
      "0.0002746585241853574\n",
      "0.00023045523108226396\n",
      "0.00036394943586002024\n",
      "0.00028134210313394666\n",
      "0.0002721144871331884\n",
      "0.00043884616650426833\n",
      "0.0005041621111422393\n",
      "0.0004039860372885409\n",
      "0.00027847180675105325\n",
      "0.00017775071390545118\n",
      "0.00020489437819898017\n",
      "0.00018291117407284792\n",
      "0.00018003832764530486\n",
      "0.000438881342629788\n",
      "0.0002667235337860153\n",
      "0.00015471561914030834\n",
      "0.00022137912382331627\n",
      "0.00023440905863156216\n",
      "0.0003191234916965803\n",
      "0.0003413290014848901\n",
      "0.00034059706479408946\n",
      "0.00021451236667554977\n",
      "0.0001736796818901037\n",
      "9.389934578766379e-05\n",
      "0.00015197636947133337\n",
      "0.00019070364562748032\n",
      "0.0001865547836879876\n",
      "0.00012465551495053164\n",
      "0.00011282038443452398\n",
      "0.00015420221652881797\n",
      "0.0002508593823885201\n",
      "0.00023584863710813327\n",
      "0.0001433800037346375\n",
      "0.00019410098733117523\n",
      "0.00017563443688601075\n",
      "0.00013118805008231307\n",
      "0.00020376406402147258\n",
      "0.00016204970136258896\n",
      "0.000185690794752144\n",
      "0.00021941111502890047\n",
      "0.0001525490771267373\n",
      "9.161009283341387e-05\n",
      "0.0001490110643089781\n",
      "0.00021410283832897422\n",
      "0.00018835215947992542\n",
      "0.00020566927638340578\n",
      "0.00016179202780317408\n",
      "0.00013346351956043507\n",
      "0.00014549748481612157\n",
      "0.00010183567520223507\n",
      "0.00018814031203823216\n",
      "0.00012569202527098027\n",
      "0.00016333144057167814\n",
      "0.00016282292251297776\n",
      "0.00010635190724106064\n",
      "0.0001274026008350928\n",
      "0.00014577503280616092\n",
      "0.00018354047954453138\n",
      "0.0001984101302195055\n",
      "0.00030157324653825386\n",
      "0.00022615011532972648\n",
      "0.00014578242661487194\n",
      "0.00013977922817632368\n",
      "0.00018477484009487037\n",
      "0.00019798835009033928\n",
      "0.00027019657229776457\n",
      "0.0001727865665096525\n",
      "0.00010495939285971245\n",
      "0.00012817328720413597\n",
      "0.00020741890833434628\n",
      "0.00021037057224061138\n",
      "9.80106775081322e-05\n",
      "0.00026728250103721923\n",
      "0.0002464675014354399\n",
      "0.00023383321016628102\n",
      "0.00018596986671694124\n",
      "0.0002277497104439541\n",
      "0.000259546961844768\n",
      "0.00023033474628184278\n",
      "0.00019537493077404242\n",
      "0.0001608154059620798\n",
      "0.00028778445696791194\n",
      "0.0004178776871071586\n",
      "0.0003119680958050783\n",
      "0.00015197538969965492\n",
      "0.0001131430025774884\n",
      "0.00017482894392911911\n",
      "0.00017563041471054265\n",
      "0.00027587849307924764\n",
      "0.00020860793192058717\n",
      "0.00013206716470020655\n",
      "0.0001513439455633513\n",
      "8.968709572941696e-05\n",
      "0.00020738649840655731\n",
      "0.0003563347392873856\n",
      "0.0002355143468158986\n",
      "0.00024287653658463095\n",
      "0.00022285927948987564\n",
      "0.00018872088514213303\n",
      "0.00015095939816819575\n",
      "0.00019897225691756332\n",
      "0.00024216725903945232\n",
      "0.0001477068758849184\n",
      "0.0002148932246027281\n",
      "0.00031301780456861834\n",
      "0.0002249346949603136\n",
      "0.00019207960478193818\n",
      "0.00015470234923584152\n",
      "0.00026361170644810235\n",
      "0.0002539948821477119\n",
      "0.00014121832870609685\n",
      "0.000141457662580477\n",
      "0.0001612870950681854\n",
      "0.00011770316606730678\n",
      "0.0001405569564527056\n",
      "0.0002119426374200863\n",
      "0.0003084273983168467\n",
      "0.00022499494853252093\n",
      "0.00012069199398523893\n",
      "0.00025815819501992233\n",
      "0.00034052600637622476\n",
      "0.000509087301203951\n",
      "0.0003025636050222909\n",
      "0.0001689132307876151\n",
      "0.0002009844537220294\n",
      "9.961680608215501e-05\n",
      "9.931578158351469e-05\n",
      "0.0001466352233594581\n",
      "0.00015957950658157608\n",
      "0.00010557451131759684\n",
      "0.00010511019651097915\n",
      "0.00013543092891668006\n",
      "0.0001420462810405263\n",
      "0.0001632517424600647\n",
      "0.00018725546361317286\n",
      "0.00032870102243752225\n",
      "0.00030039355020462745\n",
      "0.0002628805366264324\n",
      "0.00016530953947276189\n",
      "0.00017273914415904734\n",
      "0.00016535289598730227\n",
      "0.00016934541113542873\n",
      "0.00021551248488661887\n",
      "0.00029636589586624814\n",
      "0.0002599334571861259\n",
      "0.0002500967550360349\n",
      "0.00018782906426591974\n",
      "8.517610594794203e-05\n",
      "9.585491158530806e-05\n",
      "0.00013649583509952668\n",
      "0.00016412072407017664\n",
      "0.00020543459973124364\n",
      "0.0002034243942779305\n",
      "0.00012828145679359115\n",
      "0.0001386972349801286\n",
      "8.214748630238741e-05\n",
      "0.0001615398976321855\n",
      "0.00021849268732127109\n",
      "0.00023336613095180259\n",
      "0.0001972780511880846\n",
      "0.00014787317303410194\n",
      "0.00018091079432938536\n",
      "0.00012948157265536142\n",
      "0.00012503650253269149\n",
      "0.00015777392529410297\n",
      "0.00010175996467472979\n",
      "0.00015619282649456033\n",
      "0.00016885625615656742\n",
      "0.0002188565228143\n",
      "0.00018276548525920165\n",
      "0.00010512957337743063\n",
      "0.00015086587147528175\n",
      "0.0002542545156398403\n",
      "0.00027043744888960447\n",
      "0.0001569768586062064\n",
      "0.0001492200502270982\n",
      "0.00011799822009066981\n",
      "0.00014509443995360793\n",
      "0.0002136653056194512\n",
      "0.00013656919399024505\n",
      "0.00029003771307803275\n",
      "0.0002894623256232313\n",
      "0.00015864546586442376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00022239870661358468\n",
      "0.00025408527779623066\n",
      "0.00025061486111006647\n",
      "0.0002871199177654955\n",
      "0.000367434710191648\n",
      "0.00021734235412541476\n",
      "0.00023303910742104324\n",
      "0.00016121140113598562\n",
      "0.00019585721313522178\n",
      "0.00016373579627130036\n",
      "0.00016398405847186198\n",
      "0.0001366261479924871\n",
      "0.00012908929559437128\n",
      "0.00017692326886561058\n",
      "0.0001736573906865284\n",
      "0.00014984844290527035\n",
      "0.00010687506379716674\n",
      "0.0001364456125217343\n",
      "0.00013681844000756787\n",
      "0.00017569820393609957\n",
      "0.00019210162991088183\n",
      "0.00015450105241018183\n",
      "0.0002769537798833398\n",
      "0.00028397783933531347\n",
      "0.0002727112239920855\n",
      "Epoch: 7; train loss: 0.4342500811766182; train accuracy: 0.8491855053191489; test accuracy: 0.8315\n",
      "0.00017842279081901064\n",
      "0.00011811955460707909\n",
      "0.00011091462962174176\n",
      "0.0002834656459378035\n",
      "0.00041968751440848057\n",
      "0.00034107747222641505\n",
      "0.00018211392680166617\n",
      "0.00019263659040051506\n",
      "0.00017108872323105026\n",
      "0.00015779120342382984\n",
      "0.00024904868262725125\n",
      "0.00014230754763100168\n",
      "0.0001432164871442045\n",
      "0.00018934712853820742\n",
      "0.0002580265175371742\n",
      "0.00021361502504012436\n",
      "0.00011138011688056987\n",
      "0.00013920850948098416\n",
      "0.00014934929301396748\n",
      "9.671090558966063e-05\n",
      "0.00016122481409789355\n",
      "0.00022873391616970483\n",
      "0.00020604870950117942\n",
      "9.397701687422181e-05\n",
      "0.00017493648900141534\n",
      "0.00022632563393561826\n",
      "0.0002241848475186703\n",
      "0.0002750133747604514\n",
      "0.0002308930416542172\n",
      "0.00036662613907279993\n",
      "0.0002818972702051879\n",
      "0.000270863782432186\n",
      "0.000438552730966095\n",
      "0.0005084385877110132\n",
      "0.00041204739724197756\n",
      "0.00028276591329849324\n",
      "0.0001738851123750779\n",
      "0.00020414084577554222\n",
      "0.0001892197528385608\n",
      "0.0001883095378485598\n",
      "0.0004484397098581345\n",
      "0.0002691934919067282\n",
      "0.00016081901275465782\n",
      "0.00022863074387721963\n",
      "0.00024029456811416305\n",
      "0.0003278087029384107\n",
      "0.0003441633070875919\n",
      "0.00033523549384278684\n",
      "0.00020819016762422046\n",
      "0.00017127524560389112\n",
      "9.039790209492207e-05\n",
      "0.00015391548664014256\n",
      "0.00019180542752577167\n",
      "0.00018607043850378766\n",
      "0.00012188862388424613\n",
      "0.0001165906575429347\n",
      "0.00015784922700348198\n",
      "0.00025198529486267375\n",
      "0.00023731163758309182\n",
      "0.00014835156905971175\n",
      "0.0001977573850364384\n",
      "0.00017916620836254228\n",
      "0.0001332714700726847\n",
      "0.000208700497805152\n",
      "0.0001633306900940233\n",
      "0.00018911332081352126\n",
      "0.00022315460313897421\n",
      "0.00015440752070252058\n",
      "9.310570313765963e-05\n",
      "0.0001510479838960668\n",
      "0.00021946271548918628\n",
      "0.0001919150656324715\n",
      "0.0002057264169574644\n",
      "0.00016353728695949802\n",
      "0.00013164741478239353\n",
      "0.00014339782464640045\n",
      "0.00010050537230241326\n",
      "0.0001973240719690664\n",
      "0.0001317922909965467\n",
      "0.00016672513476458916\n",
      "0.00016879580990009318\n",
      "0.00011051881313969696\n",
      "0.0001290210563564834\n",
      "0.00014810520285364498\n",
      "0.00019174420259695864\n",
      "0.00020192128207575772\n",
      "0.0003017254901512276\n",
      "0.00022642683571048815\n",
      "0.00015050860488897275\n",
      "0.00014495235417393376\n",
      "0.00019474505279802173\n",
      "0.00019760515698128282\n",
      "0.00026924660663215673\n",
      "0.0001729828634857644\n",
      "0.00010745320129677854\n",
      "0.0001330529811618107\n",
      "0.0002113630148675339\n",
      "0.00020833300148392127\n",
      "9.800514802430095e-05\n",
      "0.00027257656100850404\n",
      "0.00025091517674249574\n",
      "0.00023191036438332453\n",
      "0.00018347192666690786\n",
      "0.0002319142567322313\n",
      "0.0002601531401464868\n",
      "0.00023239535922289726\n",
      "0.000201064856712532\n",
      "0.00015973111068430293\n",
      "0.0002966190701212254\n",
      "0.0004252256969100288\n",
      "0.00030991031010915417\n",
      "0.00014243885588430716\n",
      "0.00011112381081122408\n",
      "0.00018941495878795354\n",
      "0.00017794997804742926\n",
      "0.0002781100875363306\n",
      "0.00020925807256261445\n",
      "0.00013374266296563574\n",
      "0.00015616121615047833\n",
      "8.94426893678565e-05\n",
      "0.00020988367818790203\n",
      "0.00036107210426464996\n",
      "0.00023723959975663122\n",
      "0.00024583409988780555\n",
      "0.0002224967233094411\n",
      "0.00019850827025443902\n",
      "0.00016174990768312933\n",
      "0.00019997713589714098\n",
      "0.00024159421039143044\n",
      "0.0001433770996618846\n",
      "0.00022668497594235785\n",
      "0.0003216232251108657\n",
      "0.0002255059188476206\n",
      "0.00019392623061039002\n",
      "0.0001579071554065245\n",
      "0.00026737959792624925\n",
      "0.0002605036673723922\n",
      "0.00014456996861159557\n",
      "0.0001405027449449456\n",
      "0.00015996634389974364\n",
      "0.0001193836532817329\n",
      "0.00014694199878997059\n",
      "0.00021355579267743024\n",
      "0.00030097609449251624\n",
      "0.0002157464102297614\n",
      "0.00012761592709694777\n",
      "0.0002602493775371965\n",
      "0.00034513636756796685\n",
      "0.0005159855021612295\n",
      "0.00030443920279229505\n",
      "0.0001733369598454565\n",
      "0.00020469017664589574\n",
      "0.00010331085823174867\n",
      "9.819846636052265e-05\n",
      "0.00014864766821044408\n",
      "0.0001645681462110799\n",
      "0.00010893694066159757\n",
      "0.00010730348364433079\n",
      "0.00014101898404677378\n",
      "0.00014728942790382163\n",
      "0.00016755722491321637\n",
      "0.0001923412266047487\n",
      "0.0003339337235961003\n",
      "0.00030220169940565176\n",
      "0.00026215047601616594\n",
      "0.00016507611250634149\n",
      "0.0001739551751992081\n",
      "0.00016363675602525677\n",
      "0.00016852185918069887\n",
      "0.00021990749286350037\n",
      "0.00030251717979905393\n",
      "0.00026581037713987527\n",
      "0.0002548481250227346\n",
      "0.00019036729023810456\n",
      "8.710188699588672e-05\n",
      "9.800964374225003e-05\n",
      "0.00014033566546843015\n",
      "0.0001674275905377389\n",
      "0.00021099555649826035\n",
      "0.00020844031781605681\n",
      "0.00013224361214077038\n",
      "0.00013979497953911768\n",
      "8.294205307618565e-05\n",
      "0.0001646876122855056\n",
      "0.00022194477451496092\n",
      "0.00023622729596989945\n",
      "0.0001965120332565665\n",
      "0.00015012433477989268\n",
      "0.00018656057706843975\n",
      "0.00013016457074530925\n",
      "0.00012491098808127202\n",
      "0.0001546505653380714\n",
      "9.989532459324874e-05\n",
      "0.0001637126022905057\n",
      "0.00017298966391005092\n",
      "0.0002211085739991364\n",
      "0.00018240324394811337\n",
      "0.00010584490924806448\n",
      "0.00015371862244764243\n",
      "0.0002613563540534988\n",
      "0.00027290362933050005\n",
      "0.00015873483996408405\n",
      "0.00015509957148201727\n",
      "0.00012169032467423794\n",
      "0.00015157882291214918\n",
      "0.00021856875449633107\n",
      "0.00013968326630319134\n",
      "0.0002929689813377928\n",
      "0.00029064315750646\n",
      "0.0001623529950826952\n",
      "0.00023123692436682858\n",
      "0.00025996473146399073\n",
      "0.0002560488255380427\n",
      "0.0002879719047810805\n",
      "0.0003685687314831779\n",
      "0.00021674698839913538\n",
      "0.00023628348522577056\n",
      "0.0001621444835950009\n",
      "0.0001978496008422908\n",
      "0.00016525788195935378\n",
      "0.00016669042558055836\n",
      "0.00013559842986651905\n",
      "0.0001268898506462008\n",
      "0.00017685575424033787\n",
      "0.0001786905945718811\n",
      "0.00015549266942368087\n",
      "0.00010746935061139167\n",
      "0.00013936584858465655\n",
      "0.00014108770015559637\n",
      "0.0001796987330897764\n",
      "0.0001945894655915625\n",
      "0.00015842973528879336\n",
      "0.0002799529245756777\n",
      "0.0002854099636725939\n",
      "0.0002723205303039439\n",
      "Epoch: 8; train loss: 0.42814763006015544; train accuracy: 0.8515791223404255; test accuracy: 0.8342\n",
      "0.00017842617800524466\n",
      "0.00012193186022817642\n",
      "0.0001141471769759887\n",
      "0.00028852666959912213\n",
      "0.0004159435248183208\n",
      "0.0003356421037027872\n",
      "0.0001811000819240302\n",
      "0.00019443187394828406\n",
      "0.00017637349448392179\n",
      "0.00016046546759853616\n",
      "0.00025295472607579\n",
      "0.00014393308117665647\n",
      "0.0001464757670879778\n",
      "0.00019367563064486267\n",
      "0.0002591327392360104\n",
      "0.0002161705925414896\n",
      "0.00011334285401999356\n",
      "0.00014213942136407425\n",
      "0.00015267060959692178\n",
      "9.885659526837969e-05\n",
      "0.00016632250964432736\n",
      "0.0002343817852984362\n",
      "0.00020697518571504353\n",
      "9.401984975692675e-05\n",
      "0.0001835773802340222\n",
      "0.00022805423525845437\n",
      "0.00022402041880784316\n",
      "0.0002740665769094741\n",
      "0.00023119022882997123\n",
      "0.0003706469927369242\n",
      "0.00028332404068544525\n",
      "0.00026778263702014707\n",
      "0.00043745883225017367\n",
      "0.0005114495390943363\n",
      "0.0004179794135255138\n",
      "0.0002867222926513141\n",
      "0.00016985680061512283\n",
      "0.00020386008826423234\n",
      "0.00019527382651512266\n",
      "0.00019536516910371662\n",
      "0.00045390078515253053\n",
      "0.0002696249639956983\n",
      "0.00016645314571684172\n",
      "0.00023443340508481013\n",
      "0.00024382189206150571\n",
      "0.00033299205300323104\n",
      "0.0003435633988570476\n",
      "0.00032678367598495224\n",
      "0.00019989043281164849\n",
      "0.0001681323004089501\n",
      "8.724414978637987e-05\n",
      "0.00015612007701515244\n",
      "0.0001925069882453739\n",
      "0.0001852854066819521\n",
      "0.00011913790839085256\n",
      "0.00011957556353006368\n",
      "0.0001606350979480762\n",
      "0.0002526261583277777\n",
      "0.00023820400556518888\n",
      "0.00015221767600058476\n",
      "0.00020057091947362686\n",
      "0.00018176636562704034\n",
      "0.00013427833791971848\n",
      "0.00021278866361497956\n",
      "0.00016361512351914937\n",
      "0.0001915734963741412\n",
      "0.00022552602813550245\n",
      "0.00015562242594683415\n",
      "9.48652062073888e-05\n",
      "0.0001532474499004939\n",
      "0.00022502446636658892\n",
      "0.00019616107668226317\n",
      "0.00020599898786544303\n",
      "0.00016576431680513797\n",
      "0.00013087435649544176\n",
      "0.00014201304510638184\n",
      "0.00010056416953519106\n",
      "0.0002068157072005101\n",
      "0.00013776214137719252\n",
      "0.000168717012355223\n",
      "0.0001738928595789902\n",
      "0.00011445934850408251\n",
      "0.00013148179489972845\n",
      "0.0001507323932216441\n",
      "0.00019818564695517636\n",
      "0.00020516692800315304\n",
      "0.00030223705891892867\n",
      "0.0002264305886600317\n",
      "0.00015423492553578384\n",
      "0.00014964913519257867\n",
      "0.00020249274930588193\n",
      "0.0001967891270318022\n",
      "0.00026750942182546565\n",
      "0.00017222138949537708\n",
      "0.00010905351884569415\n",
      "0.00013644937923847344\n",
      "0.0002150933314487848\n",
      "0.00020777190698112487\n",
      "9.875922093532057e-05\n",
      "0.00027628855356834494\n",
      "0.0002531901999246234\n",
      "0.00022852100870925774\n",
      "0.00018048948701198932\n",
      "0.00023542045105402079\n",
      "0.0002610698782186811\n",
      "0.00023467397139625154\n",
      "0.00020582751756973255\n",
      "0.00015879897440025824\n",
      "0.0003047625366916796\n",
      "0.0004312002489994992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00030529253481466925\n",
      "0.00013347024071139622\n",
      "0.0001118492184364835\n",
      "0.00020307598365993794\n",
      "0.00018002582823597663\n",
      "0.0002805418690162836\n",
      "0.000210308638701534\n",
      "0.0001353483814830761\n",
      "0.00016022511641631488\n",
      "8.919121874027e-05\n",
      "0.0002118777319881527\n",
      "0.00036491750743540053\n",
      "0.00023890240761953137\n",
      "0.00024766623944320865\n",
      "0.0002211167427782034\n",
      "0.000206833750672716\n",
      "0.00017031834714747863\n",
      "0.00020048855565958835\n",
      "0.0002407650848701784\n",
      "0.00013954646041046802\n",
      "0.00023761879038380706\n",
      "0.0003284473643548721\n",
      "0.00022392886619296043\n",
      "0.00019467027389080257\n",
      "0.00016060314421752363\n",
      "0.00026963986596208243\n",
      "0.00026547932301438303\n",
      "0.00014778410667532532\n",
      "0.00013936555419832985\n",
      "0.00015912029616327688\n",
      "0.00012051656288992655\n",
      "0.00015213489044236598\n",
      "0.00021491135982119866\n",
      "0.0002949641995226716\n",
      "0.0002085185096398663\n",
      "0.00013405971664943162\n",
      "0.0002614827477617862\n",
      "0.00034812896240782543\n",
      "0.0005191739352088019\n",
      "0.00030395624781161625\n",
      "0.00017645528027674553\n",
      "0.00020613949460987426\n",
      "0.00010721052717834317\n",
      "9.754684743616183e-05\n",
      "0.0001502147557499977\n",
      "0.00016889307691739914\n",
      "0.00011186101402519209\n",
      "0.00010948634518163801\n",
      "0.00014601956340751124\n",
      "0.00015133488043431547\n",
      "0.00017114155342987577\n",
      "0.000196782713813381\n",
      "0.00033846275093949807\n",
      "0.0003032806604828407\n",
      "0.00026048324071729835\n",
      "0.00016433695054621746\n",
      "0.0001749447477326334\n",
      "0.0001614916864985047\n",
      "0.0001681052517984717\n",
      "0.00022472513465157364\n",
      "0.0003077626839317329\n",
      "0.00027062881462545425\n",
      "0.00025883091640519987\n",
      "0.0001921591094836567\n",
      "8.993091086411889e-05\n",
      "0.00010054365569550382\n",
      "0.00014311483734268056\n",
      "0.00016946987639754096\n",
      "0.00021505446974958852\n",
      "0.00021226278087328195\n",
      "0.00013582341251211795\n",
      "0.0001406335512251597\n",
      "8.329909999812282e-05\n",
      "0.00016737110822806074\n",
      "0.00022402341658507384\n",
      "0.0002378440767382473\n",
      "0.0001952110429161598\n",
      "0.00015291103337652427\n",
      "0.00019094619411007022\n",
      "0.0001300985696433508\n",
      "0.00012484963272266157\n",
      "0.000152616197291108\n",
      "9.888724699497832e-05\n",
      "0.00016882638272842516\n",
      "0.00017677749053478137\n",
      "0.00022325065730569577\n",
      "0.00018216360197744033\n",
      "0.00010590759360367399\n",
      "0.00015656084012170956\n",
      "0.0002676697784031432\n",
      "0.0002748788667212405\n",
      "0.00016128208652881057\n",
      "0.00015999966187442836\n",
      "0.00012468745437267526\n",
      "0.0001570949285101495\n",
      "0.0002230025141471806\n",
      "0.0001434853873401067\n",
      "0.00029567142714280616\n",
      "0.0002912373899899735\n",
      "0.00016617646521145665\n",
      "0.00023748554105176124\n",
      "0.0002635144915416274\n",
      "0.0002595436196852815\n",
      "0.00028647678618164553\n",
      "0.00036763884247977094\n",
      "0.00021587701375531832\n",
      "0.00023929135083370108\n",
      "0.0001635094566981401\n",
      "0.00019936315028641968\n",
      "0.00016644406736379737\n",
      "0.00017034276401900085\n",
      "0.00013534833628451605\n",
      "0.0001260917009393798\n",
      "0.00017712495440651952\n",
      "0.00018305011423309746\n",
      "0.00016029831084891824\n",
      "0.00010862420749116465\n",
      "0.00014216742924625853\n",
      "0.00014482473377052158\n",
      "0.00018287916309657533\n",
      "0.00019618555581699072\n",
      "0.0001623596881675606\n",
      "0.0002823427795013696\n",
      "0.00028696704481771346\n",
      "Epoch: 9; train loss: 0.4231521232437768; train accuracy: 0.8531582446808511; test accuracy: 0.836\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from IPython import display\n",
    "\n",
    "# Define the training parameters\n",
    "hidden_size = 256\n",
    "number_epochs = 10\n",
    "batch_size = 256\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Initialize the weights and biases\n",
    "model_weights0 = np.random.normal(loc=0.0, scale=0.01, size=(input_size, hidden_size))\n",
    "model_biases0 = np.zeros(hidden_size)\n",
    "model_weights1 = np.random.normal(loc=0.0, scale=0.01, size=(hidden_size, output_size))\n",
    "model_biases1 = np.random.normal(loc=0.0, scale=0.01, size=output_size)\n",
    "\n",
    "# W0 = model_weights0\n",
    "# B0 = model_biases0\n",
    "W1 = model_weights1\n",
    "# B1 = model_biases1\n",
    "\n",
    "# Initialize the loss and the accuracy for all the batches\n",
    "number_batches = int(np.ceil(number_train/batch_size))\n",
    "train_loss = np.zeros(number_batches)\n",
    "train_accuracy = np.zeros(number_batches)\n",
    "\n",
    "# Define a function to compute the forward pass\n",
    "def forward(model_inputs, model_weights0, model_biases0, model_weights1, model_biases1): \n",
    "    \n",
    "    # Compute the predicted outputs using the inputs, and the learned weights and biases\n",
    "    model_outputs0 = np.matmul(model_inputs, model_weights0) + model_biases0\n",
    "    model_outputs0[model_outputs0<0] = 0\n",
    "    model_outputs1 = np.matmul(model_outputs0, model_weights1) + model_biases1\n",
    "    \n",
    "    # Compute the conditional probabilities of each class using the softmax function\n",
    "    # (modified to avoid numerical stability issues)\n",
    "    model_outputs1 = model_outputs1-np.max(model_outputs1, axis=1)[:, np.newaxis]\n",
    "    model_exp = np.exp(model_outputs1)\n",
    "    model_softmax = model_exp/np.sum(model_exp, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    return model_outputs0, model_outputs1, model_exp, model_softmax\n",
    "\n",
    "# plt.figure(figsize=(14, 4))\n",
    "\n",
    "# Loop over the epochs\n",
    "for i in range(number_epochs):\n",
    "    \n",
    "    # Compute the forward pass\n",
    "    _, _, _, test_softmax \\\n",
    "    = forward(test_inputs, model_weights0, model_biases0, model_weights1, model_biases1)\n",
    "    \n",
    "    # Compute the classification accuracy given the true test labels\n",
    "    test_accuracy = np.mean(np.argmax(test_softmax, axis=1)==test_labels)\n",
    "    \n",
    "#     display.clear_output(wait=True)\n",
    "#     display.display(plt.gcf())\n",
    "#     plt.imshow(model_weights1.T, aspect=\"auto\", cmap=\"jet\", origin=\"lower\")\n",
    "#     plt.tight_layout()\n",
    "    \n",
    "    # Loop over the batches\n",
    "    k = 0\n",
    "    for j in range(0, number_train, batch_size):\n",
    "        \n",
    "        # Derive the end index for the current batch\n",
    "        j2 = min(j+batch_size, number_train)\n",
    "    \n",
    "        # Compute the forward pass\n",
    "        train_outputs0, train_outputs1, train_exp, train_softmax \\\n",
    "        = forward(train_inputs[j:j2, :], model_weights0, model_biases0, model_weights1, model_biases1)\n",
    "        \n",
    "        # Compute the cross-entropy loss given the true train outputs\n",
    "        # (rewritten to avoid numerical stability issues)\n",
    "#         train_loss[k] = np.mean(-np.sum(train_outputs[j:j2, :]*np.log(train_softmax), axis=1))\n",
    "        train_loss[k] = np.mean(-np.sum(train_outputs[j:j2, :]\\\n",
    "                                        *(train_outputs1-np.log(np.sum(train_exp, axis=1)[:, np.newaxis])), axis=1))        \n",
    "        \n",
    "        # Compute the classification accuracy given the true train labels\n",
    "        train_accuracy[k] = np.mean(np.argmax(train_softmax, axis=1)==train_labels[j:j2])\n",
    "        \n",
    "        # Do not need to make the last updates after computing the last loss\n",
    "        if i < number_epochs-1 or k < number_batches-1:\n",
    "            \n",
    "             # Compute the derivative of the loss wrt the output of the output layer (logit before softmax)\n",
    "            train_derivative1 = train_softmax-train_outputs[j:j2, :]\n",
    "            \n",
    "            # Derive the derivative of the loss wrt the output of the hidden layer (using the chain rule)\n",
    "            train_derivative0 = np.matmul(train_derivative1, model_weights1.T)\n",
    "            \n",
    "            # Get the real batch size\n",
    "            batch_size2 = j2-j\n",
    "            \n",
    "            print(np.std(learning_rate*np.matmul(train_inputs[j:j2, :].T, train_derivative0)/batch_size2))\n",
    "            \n",
    "            # Update the weights and biases of the output layer using gradient descent\n",
    "            model_weights1 -= learning_rate*np.matmul(train_outputs0.T, train_derivative1)/batch_size2\n",
    "            model_biases1 -= learning_rate*np.sum(train_derivative1, axis=0)/batch_size2\n",
    "            \n",
    "            # Update the weights and biases of the hidden layer using gradient descent\n",
    "            model_weights0 -= learning_rate*np.matmul(train_inputs[j:j2, :].T, train_derivative0)/batch_size2\n",
    "            model_biases0 -= learning_rate*np.sum(train_derivative0, axis=0)/batch_size2\n",
    "            \n",
    "        # Update the index\n",
    "        k = k+1\n",
    "        \n",
    "    W1 = np.dstack((W1, model_weights1))\n",
    "        \n",
    "    # Print the epoch and loss\n",
    "    print(f\"Epoch: {i}; train loss: {np.mean(train_loss)}; train accuracy: {np.mean(train_accuracy)}; test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 10, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c7ceb15310>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(np.shape(W1))\n",
    "plt.plot(W1[0, 0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.3. Implement MLP using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the training parameters\n",
    "hidden_size = 256\n",
    "number_epochs = 10\n",
    "batch_size = 256\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Initialize the model (as a feedforward NN)\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add an input with the number of features\n",
    "model.add(tf.keras.Input(shape=input_size))\n",
    "\n",
    "# Add a densely-connected NN layer with ReLU activation and with initialized weights and bias\n",
    "model.add(tf.keras.layers.Dense(hidden_size, activation=\"relu\", \\\n",
    "                                kernel_initializer=tf.initializers.RandomNormal(mean=0, stddev=0.01), \\\n",
    "                                bias_initializer=\"zeros\"))\n",
    "\n",
    "# Add another densely-connected NN layer without activation and with initialized weights and bias\n",
    "model.add(tf.keras.layers.Dense(output_size, activation=None, \\\n",
    "                                kernel_initializer=tf.initializers.RandomNormal(mean=0, stddev=0.01), \\\n",
    "                                bias_initializer=tf.initializers.RandomNormal(mean=0, stddev=0.01)))\n",
    "\n",
    "# Configure the model for training with gradient descent optimizer and cross-entropy loss\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate), \\\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \\\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model give the batch size and number of epochs\n",
    "model.fit(x=train_inputs, y=train_outputs, batch_size=batch_size, epochs=number_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.2. Implement MLP using a simple EA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; train loss: 2.301004729048659; train accuracy: 0.13789893617021276; test accuracy: 0.0951\n",
      "Epoch: 1; train loss: 2.2973307292592575; train accuracy: 0.23572695035460992; test accuracy: 0.2031\n",
      "Epoch: 2; train loss: 2.293383399927025; train accuracy: 0.28927304964539; test accuracy: 0.2561\n",
      "Epoch: 3; train loss: 2.2891155950664093; train accuracy: 0.3130596187943262; test accuracy: 0.3061\n",
      "Epoch: 4; train loss: 2.2843867807243337; train accuracy: 0.34269171099290785; test accuracy: 0.3178\n",
      "Epoch: 5; train loss: 2.279916903977923; train accuracy: 0.37185837765957447; test accuracy: 0.3581\n",
      "Epoch: 6; train loss: 2.275013204202445; train accuracy: 0.3753933953900709; test accuracy: 0.3712\n",
      "Epoch: 7; train loss: 2.2696354843855433; train accuracy: 0.373936170212766; test accuracy: 0.3677\n",
      "Epoch: 8; train loss: 2.264058615487657; train accuracy: 0.3751883865248227; test accuracy: 0.3677\n",
      "Epoch: 9; train loss: 2.2583721626738527; train accuracy: 0.38746121453900706; test accuracy: 0.3755\n"
     ]
    }
   ],
   "source": [
    "# Define the training parameters\n",
    "hidden_size = 256\n",
    "number_epochs = 10\n",
    "batch_size = 256\n",
    "mutation_scale = 0.01\n",
    "\n",
    "# Initialize the weights and biases\n",
    "model_weights0 = np.random.normal(loc=0.0, scale=0.01, size=(input_size, hidden_size))\n",
    "model_biases0 = np.zeros(hidden_size)\n",
    "model_weights1 = np.random.normal(loc=0.0, scale=0.01, size=(hidden_size, output_size))\n",
    "model_biases1 = np.random.normal(loc=0.0, scale=0.01, size=output_size)\n",
    "\n",
    "W1 = model_weights1\n",
    "\n",
    "# Initialize the loss and the accuracy for all the batches\n",
    "number_batches = int(np.ceil(number_train/batch_size))\n",
    "train_loss = np.zeros(number_batches)\n",
    "train_accuracy = np.zeros(number_batches)\n",
    "\n",
    "# Define a function to compute the forward pass\n",
    "def forward(model_inputs, model_weights0, model_biases0, model_weights1, model_biases1): \n",
    "    \n",
    "    # Compute the predicted outputs using the inputs, and the learned weights and biases\n",
    "    model_outputs0 = np.matmul(model_inputs, model_weights0) + model_biases0\n",
    "    model_outputs0[model_outputs0<0] = 0\n",
    "    model_outputs1 = np.matmul(model_outputs0, model_weights1) + model_biases1\n",
    "    \n",
    "    # Compute the conditional probabilities of each class using the softmax function\n",
    "    # (modified to avoid numerical stability issues)\n",
    "    model_outputs1 = model_outputs1-np.max(model_outputs1, axis=1)[:, np.newaxis]\n",
    "    model_exp = np.exp(model_outputs1)\n",
    "    model_softmax = model_exp/np.sum(model_exp, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    return model_outputs0, model_outputs1, model_exp, model_softmax\n",
    "\n",
    "# Loop over the epochs\n",
    "for i in range(number_epochs):\n",
    "    \n",
    "    # Compute the forward pass\n",
    "    _, _, _, test_softmax \\\n",
    "    = forward(test_inputs, model_weights0, model_biases0, model_weights1, model_biases1)\n",
    "    \n",
    "    # Compute the classification accuracy given the true test labels\n",
    "    test_accuracy = np.mean(np.argmax(test_softmax, axis=1)==test_labels)\n",
    "    \n",
    "    # Loop over the batches\n",
    "    k = 0\n",
    "    for j in range(0, number_train, batch_size):\n",
    "        \n",
    "        # Derive the end index for the current batch\n",
    "        j2 = min(j+batch_size, number_train)\n",
    "    \n",
    "        # Compute the forward pass\n",
    "        train_outputs0, train_outputs1, train_exp, train_softmax \\\n",
    "        = forward(train_inputs[j:j2, :], model_weights0, model_biases0, model_weights1, model_biases1)\n",
    "        \n",
    "        # Compute the cross-entropy loss given the true train outputs\n",
    "        # (rewritten to avoid numerical stability issues)\n",
    "#         train_loss[k] = np.mean(-np.sum(train_outputs[j:j2, :]*np.log(train_softmax), axis=1))\n",
    "        train_loss[k] = np.mean(-np.sum(train_outputs[j:j2, :]\\\n",
    "                                        *(train_outputs1-np.log(np.sum(train_exp, axis=1)[:, np.newaxis])), axis=1))\n",
    "        \n",
    "        # Compute the classification accuracy given the true train labels\n",
    "        train_accuracy[k] = np.mean(np.argmax(train_softmax, axis=1)==train_labels[j:j2])\n",
    "        \n",
    "        # Do not need to make the last updates after computing the last loss\n",
    "        if i < number_epochs-1 or k < number_batches-1:\n",
    "            \n",
    "            # Initialize the next loss\n",
    "            train_loss2 = np.inf\n",
    "            \n",
    "            # While the next loss is higher\n",
    "            while train_loss2 >= train_loss[k]:\n",
    "                \n",
    "                # Mutate the weights and biases\n",
    "                model_weights02 = model_weights0 + np.random.normal(loc=0.0, scale=mutation_scale*np.std(model_weights0), size=(input_size, hidden_size))\n",
    "                model_biases02 = model_biases0 + np.random.normal(loc=0.0, scale=mutation_scale*np.std(model_biases0), size=hidden_size)\n",
    "                model_weights12 = model_weights1 + np.random.normal(loc=0.0, scale=mutation_scale*np.std(model_weights1), size=(hidden_size, output_size))\n",
    "                model_biases12 = model_biases1 + np.random.normal(loc=0.0, scale=mutation_scale*np.std(model_biases1), size=output_size)\n",
    "                \n",
    "                # Compute the new outputs and loss\n",
    "                _, train_outputs1, train_exp, train_softmax \\\n",
    "                = forward(train_inputs[j:j2, :], model_weights02, model_biases02, model_weights12, model_biases12)\n",
    "                train_loss2 = np.mean(-np.sum(train_outputs[j:j2, :]\\\n",
    "                                                *(train_outputs1-np.log(np.sum(train_exp, axis=1)[:, np.newaxis])), axis=1))\n",
    "                train_accuracy2 = np.mean(np.argmax(train_softmax, axis=1)==train_labels[j:j2])\n",
    "                \n",
    "            # Update the weights, biases, and loss\n",
    "            model_weights0 = model_weights02\n",
    "            model_biases0 = model_biases02\n",
    "            model_weights1 = model_weights12\n",
    "            model_biases1 = model_biases12\n",
    "            train_loss[k] = train_loss2\n",
    "            train_accuracy[k] = train_accuracy2\n",
    "        \n",
    "        # Update the index\n",
    "        k = k+1\n",
    "    \n",
    "    W1 = np.dstack((W1, model_weights1))\n",
    "    \n",
    "    # Print the epoch and loss\n",
    "    print(f\"Epoch: {i}; train loss: {np.mean(train_loss)}; train accuracy: {np.mean(train_accuracy)}; test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
